{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook tests the baseline performance on models pretrained on CNN/DailyMail data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter Declaration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import Namespace\n",
    "from train_abstractive import test_abs,train_abs_single\n",
    "from train_extractive import test_ext,train_single_ext\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "arg_params = {'accum_count':1,\n",
    "'alpha':0.6,\n",
    "'batch_size':140,\n",
    "'beam_size':5,\n",
    "'beta1':0.9,\n",
    "'beta2':0.999,\n",
    "'block_trigram':True,\n",
    "'dec_dropout':0.2,\n",
    "'dec_ff_size':2048,\n",
    "'dec_heads':8,\n",
    "'dec_hidden_size':768,\n",
    "'dec_layers':6,\n",
    "'enc_dropout':0.2,\n",
    "'enc_ff_size':512,\n",
    "'enc_hidden_size':512,\n",
    "'enc_layers':6,\n",
    "'encoder':'bert',\n",
    "'ext_dropout':0.2,\n",
    "'ext_ff_size':2048,\n",
    "'ext_heads':8,\n",
    "'ext_hidden_size':768,\n",
    "'ext_layers':2,\n",
    "'finetune_bert':True,\n",
    "'generator_shard_size':32,\n",
    "'gpu_ranks':[0],\n",
    "'label_smoothing':0.1,\n",
    "'large':False,\n",
    "'load_from_extractive':'',\n",
    "'lr':1,\n",
    "'lr_bert':0.002,\n",
    "'lr_dec':0.002,\n",
    "'max_grad_norm':0,\n",
    "'max_length':150,\n",
    "'max_pos':512,\n",
    "'max_tgt_len':140,\n",
    "'min_length':15,\n",
    "'optim':'adam',\n",
    "'param_init':0,\n",
    "'param_init_glorot':True,\n",
    "'recall_eval':False,\n",
    "'report_every':1,\n",
    "'report_rouge':True,\n",
    "'save_checkpoint_steps':5,\n",
    "'seed':666,\n",
    "'sep_optim':False,\n",
    "'share_emb':False,\n",
    "'temp_dir':'./temp',\n",
    "'test_all':False,\n",
    "'test_batch_size':200,\n",
    "'test_start_from':-1,\n",
    "'train_from':'',\n",
    "'train_steps':1000,\n",
    "'use_bert_emb':False,\n",
    "'use_interval':True,\n",
    "'visible_gpus':'-1',\n",
    "'warmup_steps':8000,\n",
    "'warmup_steps_bert':8000,\n",
    "'warmup_steps_dec':8000,\n",
    "'world_size':1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Evaluation (Pre-tained model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extractive Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ext_args_dict = arg_params\n",
    "ext_args_dict.update({\n",
    "    'bert_data_path':'./data/sample',\n",
    "    'log_file':'./logs/ext_baseline',\n",
    "    'model_path':'./model_files/pre_trained/ext',\n",
    "    'result_path':'./results/pre_trained/ext_baseline',\n",
    "    'test_from':'./model_files/pre_trained/ext/bertext_cnndm_transformer.pt',\n",
    "    'task':'ext',\n",
    "    'mode':'test',\n",
    "\n",
    "    'batch_size':3000,\n",
    "    'ext_dropout':0.1\n",
    "})\n",
    "\n",
    "args = Namespace(**ext_args_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(accum_count=1, alpha=0.6, batch_size=3000, beam_size=5, bert_data_path='./data/sample', beta1=0.9, beta2=0.999, block_trigram=True, dec_dropout=0.2, dec_ff_size=2048, dec_heads=8, dec_hidden_size=768, dec_layers=6, enc_dropout=0.2, enc_ff_size=512, enc_hidden_size=512, enc_layers=6, encoder='bert', ext_dropout=0.1, ext_ff_size=2048, ext_heads=8, ext_hidden_size=768, ext_layers=2, finetune_bert=True, generator_shard_size=32, gpu_ranks=[0], label_smoothing=0.1, large=False, load_from_extractive='', log_file='./logs/ext_baseline', lr=1, lr_bert=0.002, lr_dec=0.002, max_grad_norm=0, max_length=150, max_pos=512, max_tgt_len=140, min_length=15, mode='test', model_path='./model_files/pre_trained/ext', optim='adam', param_init=0, param_init_glorot=True, recall_eval=False, report_every=1, report_rouge=True, result_path='./results/pre_trained/ext_baseline', save_checkpoint_steps=5, seed=666, sep_optim=False, share_emb=False, task='ext', temp_dir='./temp', test_all=False, test_batch_size=200, test_from='./model_files/pre_trained/ext/bertext_cnndm_transformer.pt', test_start_from=-1, train_from='', train_steps=1000, use_bert_emb=False, use_interval=True, visible_gpus='-1', warmup_steps=8000, warmup_steps_bert=8000, warmup_steps_dec=8000, world_size=1)\n",
      "pts ['./data/sample/test.pt']\n",
      "gpu_rank 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-05-09 18:11:10,849 [MainThread  ] [INFO ]  Writing summaries.\n",
      "2020-05-09 18:11:10,853 [MainThread  ] [INFO ]  Processing summaries. Saving system files to ./temp/tmp6j_sjx3p/system and model files to ./temp/tmp6j_sjx3p/model.\n",
      "2020-05-09 18:11:10,855 [MainThread  ] [INFO ]  Processing files in ./temp/rouge-tmp-2020-05-09-18-11-10/candidate/.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-05-09 18:11:10,966 [MainThread  ] [INFO ]  Saved processed files to ./temp/tmp6j_sjx3p/system.\n",
      "2020-05-09 18:11:10,968 [MainThread  ] [INFO ]  Processing files in ./temp/rouge-tmp-2020-05-09-18-11-10/reference/.\n",
      "2020-05-09 18:11:11,058 [MainThread  ] [INFO ]  Saved processed files to ./temp/tmp6j_sjx3p/model.\n",
      "2020-05-09 18:11:11,069 [MainThread  ] [INFO ]  Written ROUGE configuration to ./temp/tmpkg017wsj/rouge_conf.xml\n",
      "2020-05-09 18:11:11,071 [MainThread  ] [INFO ]  Running ROUGE with command perl ./ROUGE-1.5.5/ROUGE-1.5.5.pl -e ./ROUGE-1.5.5/data -c 95 -m -r 1000 -n 2 -a ./temp/tmpkg017wsj/rouge_conf.xml\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------\n",
      "1 ROUGE-1 Average_R: 0.20328 (95%-conf.int. 0.15639 - 0.24953)\n",
      "1 ROUGE-1 Average_P: 0.51021 (95%-conf.int. 0.44358 - 0.57656)\n",
      "1 ROUGE-1 Average_F: 0.27355 (95%-conf.int. 0.22923 - 0.31203)\n",
      "---------------------------------------------\n",
      "1 ROUGE-2 Average_R: 0.05501 (95%-conf.int. 0.03840 - 0.07312)\n",
      "1 ROUGE-2 Average_P: 0.15724 (95%-conf.int. 0.10938 - 0.20544)\n",
      "1 ROUGE-2 Average_F: 0.07810 (95%-conf.int. 0.05404 - 0.10198)\n",
      "---------------------------------------------\n",
      "1 ROUGE-L Average_R: 0.17241 (95%-conf.int. 0.13743 - 0.20633)\n",
      "1 ROUGE-L Average_P: 0.44482 (95%-conf.int. 0.37828 - 0.51036)\n",
      "1 ROUGE-L Average_F: 0.23461 (95%-conf.int. 0.19935 - 0.26841)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_ext(args, device_id=-1, pt=args.test_from, step=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abstractive Summarization (Bert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "abs_args_dict = arg_params\n",
    "\n",
    "abs_args_dict.update({\n",
    "    'bert_data_path':'./data/sample',\n",
    "    'log_file':'./logs/abs_bertextabs',\n",
    "    'model_path':'./model_files/pre_trained/abs_bertextabs/',\n",
    "    'result_path':'./results/pre_trained/abs_bertextabs',\n",
    "    'test_from':'./model_files/pre_trained/abs_bertextabs/model_step_148000.pt',\n",
    "    'task':'abs',\n",
    "    'mode':'test',\n",
    "    \n",
    "    'batch_size':3000,\n",
    "    'test_batch_size':500,\n",
    "    'max_pos':512,\n",
    "    'max_length':200,\n",
    "    'alpha': 0.95,\n",
    "    'min_length':50,\n",
    "        \n",
    "    'sep_optim':True,\n",
    "    'user_interval':True\n",
    "\n",
    "})\n",
    "\n",
    "\n",
    "args = Namespace(**abs_args_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(accum_count=1, alpha=0.95, batch_size=3000, beam_size=5, bert_data_path='./data/sample', beta1=0.9, beta2=0.999, block_trigram=True, dec_dropout=0.2, dec_ff_size=2048, dec_heads=8, dec_hidden_size=768, dec_layers=6, enc_dropout=0.2, enc_ff_size=512, enc_hidden_size=512, enc_layers=6, encoder='bert', ext_dropout=0.1, ext_ff_size=2048, ext_heads=8, ext_hidden_size=768, ext_layers=2, finetune_bert=True, generator_shard_size=32, gpu_ranks=[0], label_smoothing=0.1, large=False, load_from_extractive='', log_file='./logs/abs_bertextabs', lr=1, lr_bert=0.002, lr_dec=0.002, max_grad_norm=0, max_length=200, max_pos=512, max_tgt_len=140, min_length=50, mode='test', model_path='./model_files/pre_trained/abs_bertextabs/', optim='adam', param_init=0, param_init_glorot=True, recall_eval=False, report_every=1, report_rouge=True, result_path='./results/pre_trained/abs_bertextabs', save_checkpoint_steps=5, seed=666, sep_optim=True, share_emb=False, task='abs', temp_dir='./temp', test_all=False, test_batch_size=500, test_from='./model_files/pre_trained/abs_bertextabs/model_step_148000.pt', test_start_from=-1, train_from='', train_steps=1000, use_bert_emb=False, use_interval=True, user_interval=True, visible_gpus='-1', warmup_steps=8000, warmup_steps_bert=8000, warmup_steps_dec=8000, world_size=1)\n",
      "pts ['./data/sample/test.pt']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-05-09 18:13:05,289 [MainThread  ] [INFO ]  Writing summaries.\n",
      "2020-05-09 18:13:05,293 [MainThread  ] [INFO ]  Processing summaries. Saving system files to ./temp/tmpt_dbj0bv/system and model files to ./temp/tmpt_dbj0bv/model.\n",
      "2020-05-09 18:13:05,297 [MainThread  ] [INFO ]  Processing files in ./temp/rouge-tmp-2020-05-09-18-13-05/candidate/.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-05-09 18:13:05,427 [MainThread  ] [INFO ]  Saved processed files to ./temp/tmpt_dbj0bv/system.\n",
      "2020-05-09 18:13:05,429 [MainThread  ] [INFO ]  Processing files in ./temp/rouge-tmp-2020-05-09-18-13-05/reference/.\n",
      "2020-05-09 18:13:05,478 [MainThread  ] [INFO ]  Saved processed files to ./temp/tmpt_dbj0bv/model.\n",
      "2020-05-09 18:13:05,493 [MainThread  ] [INFO ]  Written ROUGE configuration to ./temp/tmp3_p7nbja/rouge_conf.xml\n",
      "2020-05-09 18:13:05,495 [MainThread  ] [INFO ]  Running ROUGE with command perl ./ROUGE-1.5.5/ROUGE-1.5.5.pl -e ./ROUGE-1.5.5/data -c 95 -m -r 1000 -n 2 -a ./temp/tmp3_p7nbja/rouge_conf.xml\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------\n",
      "1 ROUGE-1 Average_R: 0.16549 (95%-conf.int. 0.12668 - 0.20999)\n",
      "1 ROUGE-1 Average_P: 0.49143 (95%-conf.int. 0.43429 - 0.54958)\n",
      "1 ROUGE-1 Average_F: 0.23562 (95%-conf.int. 0.19439 - 0.27773)\n",
      "---------------------------------------------\n",
      "1 ROUGE-2 Average_R: 0.03845 (95%-conf.int. 0.02406 - 0.05539)\n",
      "1 ROUGE-2 Average_P: 0.12827 (95%-conf.int. 0.07970 - 0.18200)\n",
      "1 ROUGE-2 Average_F: 0.05670 (95%-conf.int. 0.03542 - 0.08007)\n",
      "---------------------------------------------\n",
      "1 ROUGE-L Average_R: 0.13891 (95%-conf.int. 0.10795 - 0.17146)\n",
      "1 ROUGE-L Average_P: 0.41978 (95%-conf.int. 0.36259 - 0.47673)\n",
      "1 ROUGE-L Average_F: 0.19938 (95%-conf.int. 0.16438 - 0.23293)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_abs(args, device_id=-1, pt=args.test_from, step=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abstractive Summarization (Transformers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(accum_count=1, alpha=0.95, batch_size=3000, beam_size=5, bert_data_path='./data/sample', beta1=0.9, beta2=0.999, block_trigram=True, dec_dropout=0.2, dec_ff_size=2048, dec_heads=8, dec_hidden_size=512, dec_layers=6, enc_dropout=0.2, enc_ff_size=2048, enc_hidden_size=512, enc_layers=6, encoder='baseline', ext_dropout=0.1, ext_ff_size=2048, ext_heads=8, ext_hidden_size=768, ext_layers=2, finetune_bert=True, generator_shard_size=32, gpu_ranks=[0], label_smoothing=0.1, large=False, load_from_extractive='', log_file='./logs/abs_transformers', lr=1, lr_bert=0.002, lr_dec=0.002, max_grad_norm=0, max_length=200, max_pos=512, max_tgt_len=140, min_length=50, mode='test', model_path='./model_files/pre_trained/abs_transformer/', optim='adam', param_init=0, param_init_glorot=True, recall_eval=False, report_every=1, report_rouge=True, result_path='./results/pre_trained/abs_transformer', save_checkpoint_steps=5, seed=666, sep_optim=False, share_emb=False, task='abs', temp_dir='./temp', test_all=False, test_batch_size=500, test_from='./model_files/pre_trained/abs_transformer/cnndm_baseline_best.pt', test_start_from=-1, train_from='', train_steps=1000, use_bert_emb=False, use_interval=True, user_interval=True, visible_gpus='-1', warmup_steps=8000, warmup_steps_bert=8000, warmup_steps_dec=8000, world_size=1)\n",
      "pts ['./data/sample/test.pt']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-05-09 18:14:15,030 [MainThread  ] [INFO ]  Writing summaries.\n",
      "2020-05-09 18:14:15,033 [MainThread  ] [INFO ]  Processing summaries. Saving system files to ./temp/tmp53jv26k6/system and model files to ./temp/tmp53jv26k6/model.\n",
      "2020-05-09 18:14:15,035 [MainThread  ] [INFO ]  Processing files in ./temp/rouge-tmp-2020-05-09-18-14-14/candidate/.\n",
      "2020-05-09 18:14:15,126 [MainThread  ] [INFO ]  Saved processed files to ./temp/tmp53jv26k6/system.\n",
      "2020-05-09 18:14:15,128 [MainThread  ] [INFO ]  Processing files in ./temp/rouge-tmp-2020-05-09-18-14-14/reference/.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-05-09 18:14:15,158 [MainThread  ] [INFO ]  Saved processed files to ./temp/tmp53jv26k6/model.\n",
      "2020-05-09 18:14:15,168 [MainThread  ] [INFO ]  Written ROUGE configuration to ./temp/tmpvaax8pcg/rouge_conf.xml\n",
      "2020-05-09 18:14:15,169 [MainThread  ] [INFO ]  Running ROUGE with command perl ./ROUGE-1.5.5/ROUGE-1.5.5.pl -e ./ROUGE-1.5.5/data -c 95 -m -r 1000 -n 2 -a ./temp/tmpvaax8pcg/rouge_conf.xml\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------\n",
      "1 ROUGE-1 Average_R: 0.14557 (95%-conf.int. 0.11195 - 0.18793)\n",
      "1 ROUGE-1 Average_P: 0.45450 (95%-conf.int. 0.38942 - 0.53375)\n",
      "1 ROUGE-1 Average_F: 0.20731 (95%-conf.int. 0.17620 - 0.24263)\n",
      "---------------------------------------------\n",
      "1 ROUGE-2 Average_R: 0.03248 (95%-conf.int. 0.02238 - 0.04310)\n",
      "1 ROUGE-2 Average_P: 0.12522 (95%-conf.int. 0.07004 - 0.18446)\n",
      "1 ROUGE-2 Average_F: 0.04909 (95%-conf.int. 0.03241 - 0.06563)\n",
      "---------------------------------------------\n",
      "1 ROUGE-L Average_R: 0.12552 (95%-conf.int. 0.09959 - 0.15625)\n",
      "1 ROUGE-L Average_P: 0.40354 (95%-conf.int. 0.33096 - 0.48823)\n",
      "1 ROUGE-L Average_F: 0.18088 (95%-conf.int. 0.15481 - 0.21085)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "abs_args_dict = arg_params\n",
    "\n",
    "abs_args_dict.update({\n",
    "    'bert_data_path':'./data/sample',\n",
    "    'log_file':'./logs/abs_transformers',\n",
    "    'model_path':'./model_files/pre_trained/abs_transformer/',\n",
    "    'result_path':'./results/pre_trained/abs_transformer',\n",
    "    'test_from':'./model_files/pre_trained/abs_transformer/cnndm_baseline_best.pt',\n",
    "    'task':'abs',\n",
    "    'mode':'test',\n",
    "    \n",
    "    'batch_size':3000,\n",
    "    'test_batch_size':500,\n",
    "    'max_pos':512,\n",
    "    'max_length':200,\n",
    "    'min_length':50,\n",
    "        \n",
    "    'sep_optim':False,\n",
    "\n",
    "})\n",
    "\n",
    "\n",
    "args = Namespace(**abs_args_dict)\n",
    "test_abs(args, device_id=-1, pt=args.test_from, step=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training & Evaluation on Case Law Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extractive Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_steps = 5\n",
    "ext_args_train_dict = arg_params\n",
    "\n",
    "ext_args_train_dict.update({\n",
    "    \n",
    "    'bert_data_path':'./data/sample',\n",
    "    'log_file':'./logs/train_ext',\n",
    "    'mode':'train',\n",
    "    'model_path':'./model_files/trained/ext',\n",
    "    'result_path':'../results/trained/ext',\n",
    "    'train_from':'./model_files/pre_trained/ext/bertext_cnndm_transformer.pt',\n",
    "\n",
    "    'report_every':1,\n",
    "    'save_checkpoint_steps':1,\n",
    "    'batch_size':500,\n",
    "    'train_steps':18001 + training_steps,\n",
    "    'warmup_steps':1,\n",
    "    'max_pos':512,\n",
    "\n",
    "    'task':'ext',\n",
    "    'ext_dropout':0.1,\n",
    "    'lr':0.002,\n",
    "    'accum_count':2,\n",
    "    'use_interval':True\n",
    "})\n",
    "\n",
    "\n",
    "args = Namespace(**ext_args_train_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(accum_count=2, alpha=0.6, batch_size=500, beam_size=5, bert_data_path='./data/sample', beta1=0.9, beta2=0.999, block_trigram=True, dec_dropout=0.2, dec_ff_size=2048, dec_heads=8, dec_hidden_size=768, dec_layers=6, enc_dropout=0.2, enc_ff_size=512, enc_hidden_size=512, enc_layers=6, encoder='bert', ext_dropout=0.1, ext_ff_size=2048, ext_heads=8, ext_hidden_size=768, ext_layers=2, finetune_bert=True, generator_shard_size=32, gpu_ranks=[0], label_smoothing=0.1, large=False, load_from_extractive='', log_file='./logs/train_ext', lr=0.002, lr_bert=0.002, lr_dec=0.002, max_grad_norm=0, max_length=150, max_pos=512, max_tgt_len=140, min_length=15, mode='train', model_path='./model_files/trained/ext', optim='adam', param_init=0, param_init_glorot=True, recall_eval=False, report_every=1, report_rouge=True, result_path='../results/trained/ext', save_checkpoint_steps=1, seed=666, sep_optim=False, share_emb=False, task='ext', temp_dir='./temp', test_all=False, test_batch_size=200, test_start_from=-1, train_from='./model_files/pre_trained/ext/bertext_cnndm_transformer.pt', train_steps=18006, use_bert_emb=False, use_interval=True, visible_gpus='-1', warmup_steps=1, warmup_steps_bert=8000, warmup_steps_dec=8000, world_size=1)\n"
     ]
    }
   ],
   "source": [
    "print(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-05-09 18:57:40,932 INFO] Device ID -1\n",
      "[2020-05-09 18:57:40,934 INFO] Device cpu\n",
      "[2020-05-09 18:57:40,943 INFO] Loading checkpoint from ./model_files/pre_trained/ext/bertext_cnndm_transformer.pt\n",
      "[2020-05-09 18:57:45,124 INFO] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at ./temp/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
      "[2020-05-09 18:57:45,126 INFO] Model config {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "[2020-05-09 18:57:45,973 INFO] loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at ./temp/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['model', 'opt', 'optim'])\n",
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-05-09 18:57:52,763 INFO] ExtSummarizer(\n",
      "  (bert): Bert(\n",
      "    (model): BertModel(\n",
      "      (embeddings): BertEmbeddings(\n",
      "        (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
      "        (position_embeddings): Embedding(512, 768)\n",
      "        (token_type_embeddings): Embedding(2, 768)\n",
      "        (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1)\n",
      "      )\n",
      "      (encoder): BertEncoder(\n",
      "        (layer): ModuleList(\n",
      "          (0): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1)\n",
      "            )\n",
      "          )\n",
      "          (1): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1)\n",
      "            )\n",
      "          )\n",
      "          (2): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1)\n",
      "            )\n",
      "          )\n",
      "          (3): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1)\n",
      "            )\n",
      "          )\n",
      "          (4): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1)\n",
      "            )\n",
      "          )\n",
      "          (5): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1)\n",
      "            )\n",
      "          )\n",
      "          (6): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1)\n",
      "            )\n",
      "          )\n",
      "          (7): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1)\n",
      "            )\n",
      "          )\n",
      "          (8): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1)\n",
      "            )\n",
      "          )\n",
      "          (9): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1)\n",
      "            )\n",
      "          )\n",
      "          (10): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1)\n",
      "            )\n",
      "          )\n",
      "          (11): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (pooler): BertPooler(\n",
      "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (activation): Tanh()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (ext_layer): ExtTransformerEncoder(\n",
      "    (pos_emb): PositionalEncoding(\n",
      "      (dropout): Dropout(p=0.1)\n",
      "    )\n",
      "    (transformer_inter): ModuleList(\n",
      "      (0): TransformerEncoderLayer(\n",
      "        (self_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (linear_values): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (linear_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (softmax): Softmax()\n",
      "          (dropout): Dropout(p=0.1)\n",
      "          (final_linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=768, out_features=2048, bias=True)\n",
      "          (w_2): Linear(in_features=2048, out_features=768, bias=True)\n",
      "          (layer_norm): LayerNorm(torch.Size([768]), eps=1e-06, elementwise_affine=True)\n",
      "          (dropout_1): Dropout(p=0.1)\n",
      "          (dropout_2): Dropout(p=0.1)\n",
      "        )\n",
      "        (layer_norm): LayerNorm(torch.Size([768]), eps=1e-06, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1)\n",
      "      )\n",
      "      (1): TransformerEncoderLayer(\n",
      "        (self_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (linear_values): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (linear_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (softmax): Softmax()\n",
      "          (dropout): Dropout(p=0.1)\n",
      "          (final_linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=768, out_features=2048, bias=True)\n",
      "          (w_2): Linear(in_features=2048, out_features=768, bias=True)\n",
      "          (layer_norm): LayerNorm(torch.Size([768]), eps=1e-06, elementwise_affine=True)\n",
      "          (dropout_1): Dropout(p=0.1)\n",
      "          (dropout_2): Dropout(p=0.1)\n",
      "        )\n",
      "        (layer_norm): LayerNorm(torch.Size([768]), eps=1e-06, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1)\n",
      "      )\n",
      "    )\n",
      "    (dropout): Dropout(p=0.1)\n",
      "    (layer_norm): LayerNorm(torch.Size([768]), eps=1e-06, elementwise_affine=True)\n",
      "    (wo): Linear(in_features=768, out_features=1, bias=True)\n",
      "    (sigmoid): Sigmoid()\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-05-09 18:57:52,789 INFO] * number of parameters: 120512513\n",
      "[2020-05-09 18:57:52,791 INFO] Start training...\n",
      "[2020-05-09 18:57:52,809 INFO] Loading train dataset from ./data/sample/train.pt, number of examples: 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpu_rank 0\n",
      "pts ['./data/sample/train.pt']\n",
      "Step=18001, trains_steps=18006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-05-09 18:58:06,784 INFO] Step 18001/18006; xent: 1.22; lr: 0.0000149;   0 docs/s;     14 sec\n",
      "[2020-05-09 18:58:06,793 INFO] Saving checkpoint ./model_files/trained/ext/model_step_18001.pt\n",
      "[2020-05-09 18:58:27,621 INFO] Step 18002/18006; xent: 0.70; lr: 0.0000149;   0 docs/s;     35 sec\n",
      "[2020-05-09 18:58:27,670 INFO] Saving checkpoint ./model_files/trained/ext/model_step_18002.pt\n",
      "[2020-05-09 18:58:42,429 INFO] Step 18003/18006; xent: 0.46; lr: 0.0000149;   0 docs/s;     50 sec\n",
      "[2020-05-09 18:58:42,433 INFO] Saving checkpoint ./model_files/trained/ext/model_step_18003.pt\n",
      "[2020-05-09 18:58:56,433 INFO] Step 18004/18006; xent: 0.41; lr: 0.0000149;   0 docs/s;     64 sec\n",
      "[2020-05-09 18:58:56,437 INFO] Saving checkpoint ./model_files/trained/ext/model_step_18004.pt\n",
      "[2020-05-09 18:59:13,716 INFO] Step 18005/18006; xent: 1.25; lr: 0.0000149;   0 docs/s;     81 sec\n",
      "[2020-05-09 18:59:13,726 INFO] Saving checkpoint ./model_files/trained/ext/model_step_18005.pt\n",
      "[2020-05-09 18:59:14,705 INFO] Loading train dataset from ./data/sample/train.pt, number of examples: 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pts ['./data/sample/train.pt']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-05-09 18:59:35,006 INFO] Step 18006/18006; xent: 0.16; lr: 0.0000149;   0 docs/s;    102 sec\n",
      "[2020-05-09 18:59:35,014 INFO] Saving checkpoint ./model_files/trained/ext/model_step_18006.pt\n",
      "[2020-05-09 18:59:35,038 INFO] Loading train dataset from ./data/sample/train.pt, number of examples: 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pts ['./data/sample/train.pt']\n"
     ]
    }
   ],
   "source": [
    "train_single_ext(args, device_id=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-05-09 18:15:51,835 INFO] Loading checkpoint from ./model_files/trained/ext/model_step_18006.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(accum_count=2, alpha=0.95, batch_size=3000, beam_size=5, bert_data_path='./data/sample', beta1=0.9, beta2=0.999, block_trigram=True, dec_dropout=0.2, dec_ff_size=2048, dec_heads=8, dec_hidden_size=768, dec_layers=6, enc_dropout=0.2, enc_ff_size=512, enc_hidden_size=512, enc_layers=6, encoder='bert', ext_dropout=0.1, ext_ff_size=2048, ext_heads=8, ext_hidden_size=768, ext_layers=2, finetune_bert=True, generator_shard_size=32, gpu_ranks=[0], label_smoothing=0.1, large=False, load_from_extractive='', log_file='./logs/ext_trained', lr=0.002, lr_bert=0.002, lr_dec=0.002, max_grad_norm=0, max_length=200, max_pos=512, max_tgt_len=140, min_length=50, mode='test', model_path='./model_files/trained/ext', optim='adam', param_init=0, param_init_glorot=True, recall_eval=False, report_every=1, report_rouge=True, result_path='./results/trained/ext_trained', save_checkpoint_steps=1, seed=666, sep_optim=False, share_emb=False, task='ext', temp_dir='./temp', test_all=False, test_batch_size=500, test_from='./model_files/trained/ext/model_step_18006.pt', test_start_from=-1, train_from='./model_files/pre_trained/ext/bertext_cnndm_transformer.pt', train_steps=18006, use_bert_emb=False, use_interval=True, user_interval=True, visible_gpus='-1', warmup_steps=1, warmup_steps_bert=8000, warmup_steps_dec=8000, world_size=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-05-09 18:15:53,616 INFO] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at ./temp/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
      "[2020-05-09 18:15:53,619 INFO] Model config {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "[2020-05-09 18:15:54,429 INFO] loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at ./temp/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
      "[2020-05-09 18:15:56,984 INFO] Loading test dataset from ./data/sample/test.pt, number of examples: 10\n",
      "[2020-05-09 18:15:56,991 INFO] * number of parameters: 120512513\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pts ['./data/sample/test.pt']\n",
      "gpu_rank 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-05-09 18:16:10,759 [MainThread  ] [INFO ]  Writing summaries.\n",
      "[2020-05-09 18:16:10,759 INFO] Writing summaries.\n",
      "2020-05-09 18:16:10,768 [MainThread  ] [INFO ]  Processing summaries. Saving system files to ./temp/tmpd29k8se6/system and model files to ./temp/tmpd29k8se6/model.\n",
      "[2020-05-09 18:16:10,768 INFO] Processing summaries. Saving system files to ./temp/tmpd29k8se6/system and model files to ./temp/tmpd29k8se6/model.\n",
      "2020-05-09 18:16:10,774 [MainThread  ] [INFO ]  Processing files in ./temp/rouge-tmp-2020-05-09-18-16-10/candidate/.\n",
      "[2020-05-09 18:16:10,774 INFO] Processing files in ./temp/rouge-tmp-2020-05-09-18-16-10/candidate/.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-05-09 18:16:10,890 [MainThread  ] [INFO ]  Saved processed files to ./temp/tmpd29k8se6/system.\n",
      "[2020-05-09 18:16:10,890 INFO] Saved processed files to ./temp/tmpd29k8se6/system.\n",
      "2020-05-09 18:16:10,894 [MainThread  ] [INFO ]  Processing files in ./temp/rouge-tmp-2020-05-09-18-16-10/reference/.\n",
      "[2020-05-09 18:16:10,894 INFO] Processing files in ./temp/rouge-tmp-2020-05-09-18-16-10/reference/.\n",
      "2020-05-09 18:16:10,945 [MainThread  ] [INFO ]  Saved processed files to ./temp/tmpd29k8se6/model.\n",
      "[2020-05-09 18:16:10,945 INFO] Saved processed files to ./temp/tmpd29k8se6/model.\n",
      "2020-05-09 18:16:10,965 [MainThread  ] [INFO ]  Written ROUGE configuration to ./temp/tmpd9u3wegb/rouge_conf.xml\n",
      "[2020-05-09 18:16:10,965 INFO] Written ROUGE configuration to ./temp/tmpd9u3wegb/rouge_conf.xml\n",
      "2020-05-09 18:16:10,968 [MainThread  ] [INFO ]  Running ROUGE with command perl ./ROUGE-1.5.5/ROUGE-1.5.5.pl -e ./ROUGE-1.5.5/data -c 95 -m -r 1000 -n 2 -a ./temp/tmpd9u3wegb/rouge_conf.xml\n",
      "[2020-05-09 18:16:10,968 INFO] Running ROUGE with command perl ./ROUGE-1.5.5/ROUGE-1.5.5.pl -e ./ROUGE-1.5.5/data -c 95 -m -r 1000 -n 2 -a ./temp/tmpd9u3wegb/rouge_conf.xml\n",
      "[2020-05-09 18:16:12,717 INFO] Rouges at step 0 \n",
      ">> ROUGE-F(1/2/3/l): 24.61/7.30/21.23\n",
      "ROUGE-R(1/2/3/l): 16.80/4.79/14.43\n",
      "\n",
      "[2020-05-09 18:16:12,721 INFO] Validation xent: 0.906001 at step 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------\n",
      "1 ROUGE-1 Average_R: 0.16796 (95%-conf.int. 0.14317 - 0.19468)\n",
      "1 ROUGE-1 Average_P: 0.51567 (95%-conf.int. 0.44733 - 0.59079)\n",
      "1 ROUGE-1 Average_F: 0.24608 (95%-conf.int. 0.21808 - 0.27518)\n",
      "---------------------------------------------\n",
      "1 ROUGE-2 Average_R: 0.04793 (95%-conf.int. 0.03346 - 0.06227)\n",
      "1 ROUGE-2 Average_P: 0.16677 (95%-conf.int. 0.11196 - 0.22259)\n",
      "1 ROUGE-2 Average_F: 0.07300 (95%-conf.int. 0.05076 - 0.09331)\n",
      "---------------------------------------------\n",
      "1 ROUGE-L Average_R: 0.14434 (95%-conf.int. 0.12417 - 0.16737)\n",
      "1 ROUGE-L Average_P: 0.44812 (95%-conf.int. 0.37961 - 0.52312)\n",
      "1 ROUGE-L Average_F: 0.21230 (95%-conf.int. 0.18811 - 0.23831)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ext_args_dict = arg_params\n",
    "ext_args_dict.update({\n",
    "    'bert_data_path':'./data/sample',\n",
    "    'log_file':'./logs/ext_trained',\n",
    "    'model_path':'./model_files/trained/ext',\n",
    "    'result_path':'./results/trained/ext_trained',\n",
    "    'test_from':'./model_files/trained/ext/model_step_18006.pt',\n",
    "    'task':'ext',\n",
    "    'mode':'test',\n",
    "\n",
    "    'batch_size':3000,\n",
    "    'ext_dropout':0.1,\n",
    "    'accum_count':2\n",
    "})\n",
    "\n",
    "args = Namespace(**ext_args_dict)\n",
    "test_ext(args, device_id=-1, pt=args.test_from, step=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abstractive Summarization (Transformer Basline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_steps = 5\n",
    "abs_args_train_dict = arg_params\n",
    "\n",
    "abs_args_train_dict.update({\n",
    "    \n",
    "    'bert_data_path':'./data/sample',\n",
    "    'log_file':'./logs/train_abs_transformer',\n",
    "    'mode':'train',\n",
    "    'model_path':'./model_files/trained/abs_transformer',\n",
    "    'result_path':'./results/trained/abs_transformer',\n",
    "    'train_from':'./model_files/pre_trained/abs_transformer/cnndm_baseline_best.pt',\n",
    "    'task': abs,\n",
    "\n",
    "    \n",
    "    'accum_count':5,\n",
    "    'batch_size':300,\n",
    "    'dec_dropout':0.1,\n",
    "    'lr':0.05,\n",
    "    'save_checkpoint_steps':1,\n",
    "    'sep_optim':False,\n",
    "    'train_steps':38001 + training_steps,\n",
    "    'use_bert_emb':True,\n",
    "    'warmup_steps':1,\n",
    "    'report_every':50,\n",
    "    'enc_hidden_size':512 ,\n",
    "'enc_layers':6,\n",
    "'enc_ff_size': 2048,\n",
    "'enc_dropout': 0.1,\n",
    "'dec_layers': 6,\n",
    "'dec_hidden_size': 512,\n",
    "'dec_ff_size':2048,\n",
    "'encoder': 'baseline'\n",
    "\n",
    "})\n",
    "\n",
    "\n",
    "args = Namespace(**abs_args_train_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-05-09 19:11:33,690 INFO] Namespace(accum_count=5, alpha=0.6, batch_size=300, beam_size=5, bert_data_path='./data/sample', beta1=0.9, beta2=0.999, block_trigram=True, dec_dropout=0.1, dec_ff_size=2048, dec_heads=8, dec_hidden_size=512, dec_layers=6, enc_dropout=0.1, enc_ff_size=2048, enc_hidden_size=512, enc_layers=6, encoder='baseline', ext_dropout=0.2, ext_ff_size=2048, ext_heads=8, ext_hidden_size=768, ext_layers=2, finetune_bert=True, generator_shard_size=32, gpu_ranks=[0], label_smoothing=0.1, large=False, load_from_extractive='', log_file='./logs/train_abs_transformer', lr=0.05, lr_bert=0.002, lr_dec=0.002, max_grad_norm=0, max_length=150, max_pos=512, max_tgt_len=140, min_length=15, mode='train', model_path='./model_files/trained/abs_transformer', optim='adam', param_init=0, param_init_glorot=True, recall_eval=False, report_every=50, report_rouge=True, result_path='./results/trained/abs_transformer', save_checkpoint_steps=1, seed=666, sep_optim=False, share_emb=False, task=<built-in function abs>, temp_dir='./temp', test_all=False, test_batch_size=200, test_start_from=-1, train_from='./model_files/pre_trained/abs_transformer/cnndm_baseline_best.pt', train_steps=38006, use_bert_emb=True, use_interval=True, visible_gpus='-1', warmup_steps=1, warmup_steps_bert=8000, warmup_steps_dec=8000, world_size=1)\n",
      "[2020-05-09 19:11:33,692 INFO] Device ID -1\n",
      "[2020-05-09 19:11:33,694 INFO] Device cpu\n",
      "[2020-05-09 19:11:33,701 INFO] Loading checkpoint from ./model_files/pre_trained/abs_transformer/cnndm_baseline_best.pt\n",
      "[2020-05-09 19:11:35,469 INFO] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at ./temp/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
      "[2020-05-09 19:11:35,476 INFO] Model config {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "[2020-05-09 19:11:36,307 INFO] loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at ./temp/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['model', 'opt', 'optims'])\n",
      "False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-05-09 19:11:46,686 INFO] AbsSummarizer(\n",
      "  (bert): Bert(\n",
      "    (model): BertModel(\n",
      "      (embeddings): BertEmbeddings(\n",
      "        (word_embeddings): Embedding(30522, 512, padding_idx=0)\n",
      "        (position_embeddings): Embedding(512, 512)\n",
      "        (token_type_embeddings): Embedding(2, 512)\n",
      "        (LayerNorm): LayerNorm(torch.Size([512]), eps=1e-12, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1)\n",
      "      )\n",
      "      (encoder): BertEncoder(\n",
      "        (layer): ModuleList(\n",
      "          (0): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=512, out_features=512, bias=True)\n",
      "                (key): Linear(in_features=512, out_features=512, bias=True)\n",
      "                (value): Linear(in_features=512, out_features=512, bias=True)\n",
      "                (dropout): Dropout(p=0.1)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=512, out_features=512, bias=True)\n",
      "                (LayerNorm): LayerNorm(torch.Size([512]), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
      "              (LayerNorm): LayerNorm(torch.Size([512]), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1)\n",
      "            )\n",
      "          )\n",
      "          (1): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=512, out_features=512, bias=True)\n",
      "                (key): Linear(in_features=512, out_features=512, bias=True)\n",
      "                (value): Linear(in_features=512, out_features=512, bias=True)\n",
      "                (dropout): Dropout(p=0.1)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=512, out_features=512, bias=True)\n",
      "                (LayerNorm): LayerNorm(torch.Size([512]), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
      "              (LayerNorm): LayerNorm(torch.Size([512]), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1)\n",
      "            )\n",
      "          )\n",
      "          (2): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=512, out_features=512, bias=True)\n",
      "                (key): Linear(in_features=512, out_features=512, bias=True)\n",
      "                (value): Linear(in_features=512, out_features=512, bias=True)\n",
      "                (dropout): Dropout(p=0.1)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=512, out_features=512, bias=True)\n",
      "                (LayerNorm): LayerNorm(torch.Size([512]), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
      "              (LayerNorm): LayerNorm(torch.Size([512]), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1)\n",
      "            )\n",
      "          )\n",
      "          (3): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=512, out_features=512, bias=True)\n",
      "                (key): Linear(in_features=512, out_features=512, bias=True)\n",
      "                (value): Linear(in_features=512, out_features=512, bias=True)\n",
      "                (dropout): Dropout(p=0.1)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=512, out_features=512, bias=True)\n",
      "                (LayerNorm): LayerNorm(torch.Size([512]), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
      "              (LayerNorm): LayerNorm(torch.Size([512]), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1)\n",
      "            )\n",
      "          )\n",
      "          (4): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=512, out_features=512, bias=True)\n",
      "                (key): Linear(in_features=512, out_features=512, bias=True)\n",
      "                (value): Linear(in_features=512, out_features=512, bias=True)\n",
      "                (dropout): Dropout(p=0.1)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=512, out_features=512, bias=True)\n",
      "                (LayerNorm): LayerNorm(torch.Size([512]), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
      "              (LayerNorm): LayerNorm(torch.Size([512]), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1)\n",
      "            )\n",
      "          )\n",
      "          (5): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=512, out_features=512, bias=True)\n",
      "                (key): Linear(in_features=512, out_features=512, bias=True)\n",
      "                (value): Linear(in_features=512, out_features=512, bias=True)\n",
      "                (dropout): Dropout(p=0.1)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=512, out_features=512, bias=True)\n",
      "                (LayerNorm): LayerNorm(torch.Size([512]), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
      "              (LayerNorm): LayerNorm(torch.Size([512]), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (pooler): BertPooler(\n",
      "        (dense): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (activation): Tanh()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder): TransformerDecoder(\n",
      "    (embeddings): Embedding(30522, 512, padding_idx=0)\n",
      "    (pos_emb): PositionalEncoding(\n",
      "      (dropout): Dropout(p=0.1)\n",
      "    )\n",
      "    (transformer_layers): ModuleList(\n",
      "      (0): TransformerDecoderLayer(\n",
      "        (self_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (softmax): Softmax()\n",
      "          (dropout): Dropout(p=0.1)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (context_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (softmax): Softmax()\n",
      "          (dropout): Dropout(p=0.1)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)\n",
      "          (dropout_1): Dropout(p=0.1)\n",
      "          (dropout_2): Dropout(p=0.1)\n",
      "        )\n",
      "        (layer_norm_1): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)\n",
      "        (layer_norm_2): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)\n",
      "        (drop): Dropout(p=0.1)\n",
      "      )\n",
      "      (1): TransformerDecoderLayer(\n",
      "        (self_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (softmax): Softmax()\n",
      "          (dropout): Dropout(p=0.1)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (context_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (softmax): Softmax()\n",
      "          (dropout): Dropout(p=0.1)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)\n",
      "          (dropout_1): Dropout(p=0.1)\n",
      "          (dropout_2): Dropout(p=0.1)\n",
      "        )\n",
      "        (layer_norm_1): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)\n",
      "        (layer_norm_2): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)\n",
      "        (drop): Dropout(p=0.1)\n",
      "      )\n",
      "      (2): TransformerDecoderLayer(\n",
      "        (self_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (softmax): Softmax()\n",
      "          (dropout): Dropout(p=0.1)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (context_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (softmax): Softmax()\n",
      "          (dropout): Dropout(p=0.1)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)\n",
      "          (dropout_1): Dropout(p=0.1)\n",
      "          (dropout_2): Dropout(p=0.1)\n",
      "        )\n",
      "        (layer_norm_1): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)\n",
      "        (layer_norm_2): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)\n",
      "        (drop): Dropout(p=0.1)\n",
      "      )\n",
      "      (3): TransformerDecoderLayer(\n",
      "        (self_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (softmax): Softmax()\n",
      "          (dropout): Dropout(p=0.1)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (context_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (softmax): Softmax()\n",
      "          (dropout): Dropout(p=0.1)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)\n",
      "          (dropout_1): Dropout(p=0.1)\n",
      "          (dropout_2): Dropout(p=0.1)\n",
      "        )\n",
      "        (layer_norm_1): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)\n",
      "        (layer_norm_2): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)\n",
      "        (drop): Dropout(p=0.1)\n",
      "      )\n",
      "      (4): TransformerDecoderLayer(\n",
      "        (self_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (softmax): Softmax()\n",
      "          (dropout): Dropout(p=0.1)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (context_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (softmax): Softmax()\n",
      "          (dropout): Dropout(p=0.1)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)\n",
      "          (dropout_1): Dropout(p=0.1)\n",
      "          (dropout_2): Dropout(p=0.1)\n",
      "        )\n",
      "        (layer_norm_1): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)\n",
      "        (layer_norm_2): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)\n",
      "        (drop): Dropout(p=0.1)\n",
      "      )\n",
      "      (5): TransformerDecoderLayer(\n",
      "        (self_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (softmax): Softmax()\n",
      "          (dropout): Dropout(p=0.1)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (context_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (softmax): Softmax()\n",
      "          (dropout): Dropout(p=0.1)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "          (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)\n",
      "          (dropout_1): Dropout(p=0.1)\n",
      "          (dropout_2): Dropout(p=0.1)\n",
      "        )\n",
      "        (layer_norm_1): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)\n",
      "        (layer_norm_2): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)\n",
      "        (drop): Dropout(p=0.1)\n",
      "      )\n",
      "    )\n",
      "    (layer_norm): LayerNorm(torch.Size([512]), eps=1e-06, elementwise_affine=True)\n",
      "  )\n",
      "  (generator): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=30522, bias=True)\n",
      "    (1): LogSoftmax()\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-05-09 19:11:47,535 INFO] loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at ./temp/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "[2020-05-09 19:11:47,609 INFO] * number of parameters: 75951418\n",
      "[2020-05-09 19:11:47,610 INFO] Start training...\n",
      "[2020-05-09 19:11:47,630 INFO] Loading train dataset from ./data/sample/train.pt, number of examples: 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpu_rank 0\n",
      "pts ['./data/sample/train.pt']\n",
      "Step=38001, Train_steps=38006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-05-09 19:11:59,189 INFO] Saving checkpoint ./model_files/trained/abs_transformer/model_step_38001.pt\n",
      "[2020-05-09 19:12:12,470 INFO] Saving checkpoint ./model_files/trained/abs_transformer/model_step_38002.pt\n",
      "[2020-05-09 19:12:14,037 INFO] Loading train dataset from ./data/sample/train.pt, number of examples: 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pts ['./data/sample/train.pt']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-05-09 19:12:26,816 INFO] Saving checkpoint ./model_files/trained/abs_transformer/model_step_38003.pt\n",
      "[2020-05-09 19:12:41,399 INFO] Saving checkpoint ./model_files/trained/abs_transformer/model_step_38004.pt\n",
      "[2020-05-09 19:12:42,939 INFO] Loading train dataset from ./data/sample/train.pt, number of examples: 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pts ['./data/sample/train.pt']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-05-09 19:12:54,908 INFO] Saving checkpoint ./model_files/trained/abs_transformer/model_step_38005.pt\n",
      "[2020-05-09 19:13:10,843 INFO] Saving checkpoint ./model_files/trained/abs_transformer/model_step_38006.pt\n",
      "[2020-05-09 19:13:12,591 INFO] Loading train dataset from ./data/sample/train.pt, number of examples: 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pts ['./data/sample/train.pt']\n"
     ]
    }
   ],
   "source": [
    "train_abs_single(args, device_id=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-05-09 19:13:12,657 INFO] Loading checkpoint from ./model_files/trained/abs_transformer/model_step_38006.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(accum_count=5, alpha=0.6, batch_size=3000, beam_size=5, bert_data_path='./data/sample', beta1=0.9, beta2=0.999, block_trigram=True, dec_dropout=0.1, dec_ff_size=2048, dec_heads=8, dec_hidden_size=512, dec_layers=6, enc_dropout=0.1, enc_ff_size=2048, enc_hidden_size=512, enc_layers=6, encoder='baseline', ext_dropout=0.2, ext_ff_size=2048, ext_heads=8, ext_hidden_size=768, ext_layers=2, finetune_bert=True, generator_shard_size=32, gpu_ranks=[0], label_smoothing=0.1, large=False, load_from_extractive='', log_file='./logs/abs_transformers_trained', lr=0.05, lr_bert=0.002, lr_dec=0.002, max_grad_norm=0, max_length=200, max_pos=512, max_tgt_len=140, min_length=50, mode='test', model_path='./model_files/trained/abs_transformer/', optim='adam', param_init=0, param_init_glorot=True, recall_eval=False, report_every=50, report_rouge=True, result_path='./results/trained/abs_transformer', save_checkpoint_steps=1, seed=666, sep_optim=False, share_emb=False, task='abs', temp_dir='./temp', test_all=False, test_batch_size=500, test_from='./model_files/trained/abs_transformer/model_step_38006.pt', test_start_from=-1, train_from='./model_files/pre_trained/abs_transformer/cnndm_baseline_best.pt', train_steps=38006, use_bert_emb=True, use_interval=True, visible_gpus='-1', warmup_steps=1, warmup_steps_bert=8000, warmup_steps_dec=8000, world_size=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-05-09 19:13:14,032 INFO] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at ./temp/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
      "[2020-05-09 19:13:14,033 INFO] Model config {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "[2020-05-09 19:13:14,883 INFO] loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at ./temp/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
      "[2020-05-09 19:13:21,098 INFO] Loading test dataset from ./data/sample/test.pt, number of examples: 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pts ['./data/sample/test.pt']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-05-09 19:13:21,911 INFO] loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at ./temp/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "[2020-05-09 19:14:41,905 INFO] Calculating Rouge\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-05-09 19:14:42,159 [MainThread  ] [INFO ]  Writing summaries.\n",
      "[2020-05-09 19:14:42,159 INFO] Writing summaries.\n",
      "2020-05-09 19:14:42,167 [MainThread  ] [INFO ]  Processing summaries. Saving system files to ./temp/tmpv93hl9cn/system and model files to ./temp/tmpv93hl9cn/model.\n",
      "[2020-05-09 19:14:42,167 INFO] Processing summaries. Saving system files to ./temp/tmpv93hl9cn/system and model files to ./temp/tmpv93hl9cn/model.\n",
      "2020-05-09 19:14:42,172 [MainThread  ] [INFO ]  Processing files in ./temp/rouge-tmp-2020-05-09-19-14-41/candidate/.\n",
      "[2020-05-09 19:14:42,172 INFO] Processing files in ./temp/rouge-tmp-2020-05-09-19-14-41/candidate/.\n",
      "2020-05-09 19:14:42,289 [MainThread  ] [INFO ]  Saved processed files to ./temp/tmpv93hl9cn/system.\n",
      "[2020-05-09 19:14:42,289 INFO] Saved processed files to ./temp/tmpv93hl9cn/system.\n",
      "2020-05-09 19:14:42,294 [MainThread  ] [INFO ]  Processing files in ./temp/rouge-tmp-2020-05-09-19-14-41/reference/.\n",
      "[2020-05-09 19:14:42,294 INFO] Processing files in ./temp/rouge-tmp-2020-05-09-19-14-41/reference/.\n",
      "2020-05-09 19:14:42,475 [MainThread  ] [INFO ]  Saved processed files to ./temp/tmpv93hl9cn/model.\n",
      "[2020-05-09 19:14:42,475 INFO] Saved processed files to ./temp/tmpv93hl9cn/model.\n",
      "2020-05-09 19:14:42,492 [MainThread  ] [INFO ]  Written ROUGE configuration to ./temp/tmpy93nw5z5/rouge_conf.xml\n",
      "[2020-05-09 19:14:42,492 INFO] Written ROUGE configuration to ./temp/tmpy93nw5z5/rouge_conf.xml\n",
      "2020-05-09 19:14:42,497 [MainThread  ] [INFO ]  Running ROUGE with command perl ./ROUGE-1.5.5/ROUGE-1.5.5.pl -e ./ROUGE-1.5.5/data -c 95 -m -r 1000 -n 2 -a ./temp/tmpy93nw5z5/rouge_conf.xml\n",
      "[2020-05-09 19:14:42,497 INFO] Running ROUGE with command perl ./ROUGE-1.5.5/ROUGE-1.5.5.pl -e ./ROUGE-1.5.5/data -c 95 -m -r 1000 -n 2 -a ./temp/tmpy93nw5z5/rouge_conf.xml\n",
      "[2020-05-09 19:14:44,528 INFO] Rouges at step 0 \n",
      ">> ROUGE-F(1/2/3/l): 22.75/6.25/19.23\n",
      "ROUGE-R(1/2/3/l): 16.20/4.30/13.61\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------\n",
      "1 ROUGE-1 Average_R: 0.16199 (95%-conf.int. 0.11387 - 0.22174)\n",
      "1 ROUGE-1 Average_P: 0.50354 (95%-conf.int. 0.39969 - 0.61302)\n",
      "1 ROUGE-1 Average_F: 0.22750 (95%-conf.int. 0.16928 - 0.28426)\n",
      "---------------------------------------------\n",
      "1 ROUGE-2 Average_R: 0.04299 (95%-conf.int. 0.02707 - 0.05696)\n",
      "1 ROUGE-2 Average_P: 0.15478 (95%-conf.int. 0.08875 - 0.23664)\n",
      "1 ROUGE-2 Average_F: 0.06255 (95%-conf.int. 0.03977 - 0.08134)\n",
      "---------------------------------------------\n",
      "1 ROUGE-L Average_R: 0.13615 (95%-conf.int. 0.09713 - 0.18190)\n",
      "1 ROUGE-L Average_P: 0.42933 (95%-conf.int. 0.34578 - 0.51484)\n",
      "1 ROUGE-L Average_F: 0.19228 (95%-conf.int. 0.14502 - 0.23771)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "abs_args_dict = arg_params\n",
    "\n",
    "abs_args_dict.update({\n",
    "    'bert_data_path':'./data/sample',\n",
    "    'log_file':'./logs/abs_transformers_trained',\n",
    "    'model_path':'./model_files/trained/abs_transformer/',\n",
    "    'result_path':'./results/trained/abs_transformer',\n",
    "    'test_from':'./model_files/trained/abs_transformer/model_step_38006.pt',\n",
    "    'task':'abs',\n",
    "    'mode':'test',\n",
    "    \n",
    "    'batch_size':3000,\n",
    "    'test_batch_size':500,\n",
    "    'max_pos':512,\n",
    "    'max_length':200,\n",
    "    'min_length':50,\n",
    "        \n",
    "    'sep_optim':False,\n",
    "\n",
    "})\n",
    "\n",
    "\n",
    "args = Namespace(**abs_args_dict)\n",
    "test_abs(args, device_id=-1, pt=args.test_from, step=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abstractive Summarization (BertExt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_steps = 5\n",
    "abs_args_train_dict = arg_params\n",
    "\n",
    "abs_args_train_dict.update({\n",
    "    \n",
    "    'bert_data_path':'./data/sample',\n",
    "    'log_file':'./logs/train_abs',\n",
    "    'mode':'train',\n",
    "    'model_path':'./model_files/trained/abs',\n",
    "    'result_path':'./results/trained/abs',\n",
    "    'train_from':'./model_files/pre_trained/abs_bertextabs/model_step_148000.pt',\n",
    "        'load_from_extractive':'./model_files/trained/ext/model_step_18006.pt',\n",
    "\n",
    "    'task': abs,\n",
    "    'save_checkpoint_steps':1,\n",
    "    'batch_size':140,\n",
    "    'train_steps':148001+training_steps,\n",
    "    'report_every':1,\n",
    "    'accum_count':5,\n",
    "    'warmup_steps_bert':1,\n",
    "    'warmup_steps_dec':1,\n",
    "  \n",
    "'dec_dropout':0.2,\n",
    "'sep_optim':True,\n",
    "'lr_bert':0.002,\n",
    "'lr_dec':0.2,\n",
    "'use_bert_emb':True,\n",
    "'use_interval':True,\n",
    "'max_pos':512\n",
    "})\n",
    "\n",
    "\n",
    "args = Namespace(**abs_args_train_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_abs_single(args, device_id=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abs_args_dict = arg_params\n",
    "\n",
    "abs_args_dict.update({\n",
    "    'bert_data_path':'./data/sample',\n",
    "    'log_file':'./logs/abs_bertextabs_trained',\n",
    "    'model_path':'./model_files/trained/abs_bertextabs/',\n",
    "    'result_path':'./results/trained/abs_bertextabs',\n",
    "    'test_from':'./model_files/trained/abs_bertextabs/model_step_148006.pt',\n",
    "    'task':'abs',\n",
    "    'mode':'test',\n",
    "    \n",
    "    'batch_size':3000,\n",
    "    'test_batch_size':500,\n",
    "    'max_pos':512,\n",
    "    'max_length':200,\n",
    "    'alpha': 0.95,\n",
    "    'min_length':50,\n",
    "        \n",
    "    'sep_optim':True,\n",
    "    'user_interval':True\n",
    "\n",
    "})\n",
    "\n",
    "\n",
    "args = Namespace(**abs_args_dict)\n",
    "test_abs(args, device_id=-1, pt=args.test_from, step=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
