{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <img style=\"float: left; padding-right: 10px; width: 45px\" src=\"https://raw.githubusercontent.com/Harvard-IACS/2018-CS109A/master/content/styles/iacs.png\"> CS109B Data Science 2: Advanced Topics in Data Science \n",
    "\n",
    "##  Final Project: Milestone 2 - Data Science for Case Law Final Project [70 pts]\n",
    "\n",
    "\n",
    "**Harvard University**<br/>\n",
    "**Spring 2020**<br/>\n",
    "**Group Members**: Fernando Medeiros, Mohammed Gufran Pathan, and Prerna Aggarwal<br/>\n",
    "\n",
    "<hr style=\"height:2pt\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of contents\n",
    "\n",
    "1. [Overview](#overview)\n",
    "\n",
    "\n",
    "2. [Data Preparation](#data_prep)\n",
    "\n",
    "\n",
    "3. [Pre-Summ Model](#presumm)\n",
    "\n",
    " 1. [Pre-Trained Model](#pretrained_presum)\n",
    "\n",
    " 1. [Trained Model](#trained_presum)\n",
    "\n",
    "\n",
    "4. [Match-Summ Model](#matchsum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:.1px solid grey\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='overview'></a>\n",
    "\n",
    "# Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem Statement\n",
    "\n",
    "Headnotes are brief case summary statements for court cases created by commercial third parties and may be under copyright protection.\n",
    "\n",
    "For our project we use Natural Language Processing summarization algorithms to reconstruct headnotes using court case opinions as our training dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project draws heavily from two SOTA papers:\n",
    "\n",
    "(1) [Text Summarization with Pretrained Encoders](https://arxiv.org/abs/1908.08345) (a.k.a [PreSumm](https://github.com/nlpyang/PreSumm/))\n",
    "\n",
    "(2) [Extractive Summarization as Text Matching](https://arxiv.org/abs/2004.08795) (a.k.a [MatchSumm](https://github.com/maszhongming/MatchSum/))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The source code for the two papers is linked above and this project reuses the convenience functions for train, testing and metric calculation. This notebook 'from ... imports' from the code developed in the two repositories. For reference, we have added the relevant code that is imported to this repository. We have made minor changes to the code to make it work with our use-case and dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please also note that two different environments are required to run each of the two implementations we use. We've implemented our models on EC2 machines and have also included the relevant setup scripts.\n",
    "\n",
    "1) Setup script for Presumm - https://github.com/gufranpathan/case_law_g45/blob/master/presum_env_setup.sh\n",
    "\n",
    "2) Setup script for MatchSum - https://github.com/gufranpathan/case_law_g45/blob/master/matchsumm_env_setup.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:.1px solid grey\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='data_prep'></a>\n",
    "# Data Prep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use a json dataset of cases from North Carolina provided by the Harvard Law School Library Case Law Access Project. There are 97,600 cases. There are 32 columns and we focused on the case body data, specifically the opinions and headnotes. Cases can have multiple or no opinions and headnotes. We observed up to 6 opinions in some cases. Note: we performed EDA in an earlier submitted assignment and only provide basic stats in this notebook.\n",
    "\n",
    "We selected cases since 2008 with headnotes having a length of more that 150 and with majority opinions longer than the headnotes.\n",
    "\n",
    "We removed the return characters, extracted, and tokenized the opinions and headnotes from the case body data. During which we utilized the pre-processing steps from each model to label the opinions sentences. Finally, we split the data into training (80%), validation (10%), and test (10%) sets.\n",
    "\n",
    "For labeling, we compared sentences from each opinion with their headnotes, extracting those opinion sentences that increased the Rouge score to create the extractive summary. We then labeled the sentences that were included in the summary with one and zero otherwise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pre-requisities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Stanford CoreNLP**\n",
    "\n",
    "We will need Stanford CoreNLP to tokenize the data. Download it [here](https://stanfordnlp.github.io/CoreNLP/) and unzip it. Then add the following command to your bash_profile:\n",
    "```\n",
    "export CLASSPATH=/path/to/stanford-corenlp-full-2017-06-09/stanford-corenlp-3.8.0.jar\n",
    "```\n",
    "replacing `/path/to/` with the path to where you saved the `stanford-corenlp-full-2017-06-09` directory. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from others.tokenization import BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lzma\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "\n",
    "from pandas.io.json import json_normalize\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import subprocess\n",
    "import torch\n",
    "import lxml\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The raw dataset can be downloaded from [here](https://drive.google.com/drive/folders/1Dvtk_rxNK-4tXYmRWZhX2no9TrFTu8SD). We use the North Carolina Dataset. Download the dataset and place the \".xz\" file in 'data/xml'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flattening data for north_carolina.xz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fmedeiros/anaconda3/envs/cs109b_FP/lib/python3.6/site-packages/ipykernel_launcher.py:8: FutureWarning: pandas.io.json.json_normalize is deprecated, use pandas.json_normalize instead\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "base_path = \"./data/xml\"\n",
    "state='north_carolina.xz'\n",
    "f = lzma.open(os.path.join(base_path,state),\"rb\")\n",
    "state_data = f.readlines()\n",
    "f.close()\n",
    "data_json = [json.loads(line) for line in state_data]\n",
    "print(f'Flattening data for {state}')\n",
    "data = json_normalize(data_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(97600, 31)\n",
      "Index(['id', 'url', 'name', 'name_abbreviation', 'decision_date',\n",
      "       'docket_number', 'first_page', 'last_page', 'citations', 'cites_to',\n",
      "       'frontend_url', 'preview', 'volume.volume_number', 'volume.barcode',\n",
      "       'volume.url', 'reporter.url', 'reporter.full_name', 'reporter.id',\n",
      "       'court.name', 'court.id', 'court.name_abbreviation', 'court.url',\n",
      "       'court.slug', 'jurisdiction.name_long', 'jurisdiction.name',\n",
      "       'jurisdiction.whitelisted', 'jurisdiction.id', 'jurisdiction.url',\n",
      "       'jurisdiction.slug', 'casebody.status', 'casebody.data'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# here we see the shape and column names of the dataset\n",
    "print(data.shape)\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>url</th>\n",
       "      <th>name</th>\n",
       "      <th>name_abbreviation</th>\n",
       "      <th>decision_date</th>\n",
       "      <th>docket_number</th>\n",
       "      <th>first_page</th>\n",
       "      <th>last_page</th>\n",
       "      <th>citations</th>\n",
       "      <th>cites_to</th>\n",
       "      <th>...</th>\n",
       "      <th>court.url</th>\n",
       "      <th>court.slug</th>\n",
       "      <th>jurisdiction.name_long</th>\n",
       "      <th>jurisdiction.name</th>\n",
       "      <th>jurisdiction.whitelisted</th>\n",
       "      <th>jurisdiction.id</th>\n",
       "      <th>jurisdiction.url</th>\n",
       "      <th>jurisdiction.slug</th>\n",
       "      <th>casebody.status</th>\n",
       "      <th>casebody.data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1268383</td>\n",
       "      <td>https://api.capapi.org/v1/cases/1268383/</td>\n",
       "      <td>The State vs. John Owen</td>\n",
       "      <td>State v. Owen</td>\n",
       "      <td>1810-07</td>\n",
       "      <td></td>\n",
       "      <td>260</td>\n",
       "      <td>262</td>\n",
       "      <td>[{'type': 'official', 'cite': '2 Wheel. Cr. Ca...</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>https://api.capapi.org/v1/courts/nc/</td>\n",
       "      <td>nc</td>\n",
       "      <td>North Carolina</td>\n",
       "      <td>N.C.</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>https://api.capapi.org/v1/jurisdictions/nc/</td>\n",
       "      <td>nc</td>\n",
       "      <td>ok</td>\n",
       "      <td>&lt;casebody firstpage=\"260\" lastpage=\"262\" xmlns...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11956941</td>\n",
       "      <td>https://api.capapi.org/v1/cases/11956941/</td>\n",
       "      <td>DUNLOP et al. v. WEST</td>\n",
       "      <td>Dunlop v. West</td>\n",
       "      <td>1805</td>\n",
       "      <td>Case No. 4,170</td>\n",
       "      <td>93</td>\n",
       "      <td>93</td>\n",
       "      <td>[{'type': 'official', 'cite': '8 F. Cas. 93'},...</td>\n",
       "      <td>[{'cite': '2 Hayw. N. C. 346'}]</td>\n",
       "      <td>...</td>\n",
       "      <td>https://api.capapi.org/v1/courts/ccdnc/</td>\n",
       "      <td>ccdnc</td>\n",
       "      <td>North Carolina</td>\n",
       "      <td>N.C.</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>https://api.capapi.org/v1/jurisdictions/nc/</td>\n",
       "      <td>nc</td>\n",
       "      <td>ok</td>\n",
       "      <td>&lt;casebody firstpage=\"93\" lastpage=\"93\" xmlns=\"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11645357</td>\n",
       "      <td>https://api.capapi.org/v1/cases/11645357/</td>\n",
       "      <td>The FORTUNA</td>\n",
       "      <td>The Fortuna</td>\n",
       "      <td>1815</td>\n",
       "      <td>Case No. 4,954</td>\n",
       "      <td>494</td>\n",
       "      <td>500</td>\n",
       "      <td>[{'type': 'official', 'cite': '9 F. Cas. 494'}...</td>\n",
       "      <td>[{'cite': '1 Brock. 299'}, {'cite': '3 Wheat. ...</td>\n",
       "      <td>...</td>\n",
       "      <td>https://api.capapi.org/v1/courts/ccdnc/</td>\n",
       "      <td>ccdnc</td>\n",
       "      <td>North Carolina</td>\n",
       "      <td>N.C.</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>https://api.capapi.org/v1/jurisdictions/nc/</td>\n",
       "      <td>nc</td>\n",
       "      <td>ok</td>\n",
       "      <td>&lt;casebody firstpage=\"494\" lastpage=\"500\" xmlns...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11272108</td>\n",
       "      <td>https://api.capapi.org/v1/cases/11272108/</td>\n",
       "      <td>D. K. FUTCH v. ATLANTIC COAST LINE RAILROAD CO...</td>\n",
       "      <td>Futch v. Atlantic Coast Line Railroad</td>\n",
       "      <td>1919-10-15</td>\n",
       "      <td></td>\n",
       "      <td>282</td>\n",
       "      <td>284</td>\n",
       "      <td>[{'type': 'official', 'cite': '178 N.C. 282'}]</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>https://api.capapi.org/v1/courts/nc/</td>\n",
       "      <td>nc</td>\n",
       "      <td>North Carolina</td>\n",
       "      <td>N.C.</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>https://api.capapi.org/v1/jurisdictions/nc/</td>\n",
       "      <td>nc</td>\n",
       "      <td>ok</td>\n",
       "      <td>&lt;casebody firstpage=\"282\" lastpage=\"284\" xmlns...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11273534</td>\n",
       "      <td>https://api.capapi.org/v1/cases/11273534/</td>\n",
       "      <td>MRS. SUSANNA WILLIAMS v. C. G. BAILEY, B. R. B...</td>\n",
       "      <td>Williams v. Bailey</td>\n",
       "      <td>1919-12-03</td>\n",
       "      <td></td>\n",
       "      <td>630</td>\n",
       "      <td>633</td>\n",
       "      <td>[{'type': 'official', 'cite': '178 N.C. 630'}]</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>https://api.capapi.org/v1/courts/nc/</td>\n",
       "      <td>nc</td>\n",
       "      <td>North Carolina</td>\n",
       "      <td>N.C.</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>https://api.capapi.org/v1/jurisdictions/nc/</td>\n",
       "      <td>nc</td>\n",
       "      <td>ok</td>\n",
       "      <td>&lt;casebody firstpage=\"630\" lastpage=\"633\" xmlns...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                        url  \\\n",
       "0   1268383   https://api.capapi.org/v1/cases/1268383/   \n",
       "1  11956941  https://api.capapi.org/v1/cases/11956941/   \n",
       "2  11645357  https://api.capapi.org/v1/cases/11645357/   \n",
       "3  11272108  https://api.capapi.org/v1/cases/11272108/   \n",
       "4  11273534  https://api.capapi.org/v1/cases/11273534/   \n",
       "\n",
       "                                                name  \\\n",
       "0                            The State vs. John Owen   \n",
       "1                              DUNLOP et al. v. WEST   \n",
       "2                                        The FORTUNA   \n",
       "3  D. K. FUTCH v. ATLANTIC COAST LINE RAILROAD CO...   \n",
       "4  MRS. SUSANNA WILLIAMS v. C. G. BAILEY, B. R. B...   \n",
       "\n",
       "                       name_abbreviation decision_date   docket_number  \\\n",
       "0                          State v. Owen       1810-07                   \n",
       "1                         Dunlop v. West          1805  Case No. 4,170   \n",
       "2                            The Fortuna          1815  Case No. 4,954   \n",
       "3  Futch v. Atlantic Coast Line Railroad    1919-10-15                   \n",
       "4                     Williams v. Bailey    1919-12-03                   \n",
       "\n",
       "  first_page last_page                                          citations  \\\n",
       "0        260       262  [{'type': 'official', 'cite': '2 Wheel. Cr. Ca...   \n",
       "1         93        93  [{'type': 'official', 'cite': '8 F. Cas. 93'},...   \n",
       "2        494       500  [{'type': 'official', 'cite': '9 F. Cas. 494'}...   \n",
       "3        282       284     [{'type': 'official', 'cite': '178 N.C. 282'}]   \n",
       "4        630       633     [{'type': 'official', 'cite': '178 N.C. 630'}]   \n",
       "\n",
       "                                            cites_to  ...  \\\n",
       "0                                                 []  ...   \n",
       "1                    [{'cite': '2 Hayw. N. C. 346'}]  ...   \n",
       "2  [{'cite': '1 Brock. 299'}, {'cite': '3 Wheat. ...  ...   \n",
       "3                                                 []  ...   \n",
       "4                                                 []  ...   \n",
       "\n",
       "                                 court.url court.slug jurisdiction.name_long  \\\n",
       "0     https://api.capapi.org/v1/courts/nc/         nc         North Carolina   \n",
       "1  https://api.capapi.org/v1/courts/ccdnc/      ccdnc         North Carolina   \n",
       "2  https://api.capapi.org/v1/courts/ccdnc/      ccdnc         North Carolina   \n",
       "3     https://api.capapi.org/v1/courts/nc/         nc         North Carolina   \n",
       "4     https://api.capapi.org/v1/courts/nc/         nc         North Carolina   \n",
       "\n",
       "  jurisdiction.name jurisdiction.whitelisted jurisdiction.id  \\\n",
       "0              N.C.                     True               5   \n",
       "1              N.C.                     True               5   \n",
       "2              N.C.                     True               5   \n",
       "3              N.C.                     True               5   \n",
       "4              N.C.                     True               5   \n",
       "\n",
       "                              jurisdiction.url  jurisdiction.slug  \\\n",
       "0  https://api.capapi.org/v1/jurisdictions/nc/                 nc   \n",
       "1  https://api.capapi.org/v1/jurisdictions/nc/                 nc   \n",
       "2  https://api.capapi.org/v1/jurisdictions/nc/                 nc   \n",
       "3  https://api.capapi.org/v1/jurisdictions/nc/                 nc   \n",
       "4  https://api.capapi.org/v1/jurisdictions/nc/                 nc   \n",
       "\n",
       "  casebody.status                                      casebody.data  \n",
       "0              ok  <casebody firstpage=\"260\" lastpage=\"262\" xmlns...  \n",
       "1              ok  <casebody firstpage=\"93\" lastpage=\"93\" xmlns=\"...  \n",
       "2              ok  <casebody firstpage=\"494\" lastpage=\"500\" xmlns...  \n",
       "3              ok  <casebody firstpage=\"282\" lastpage=\"284\" xmlns...  \n",
       "4              ok  <casebody firstpage=\"630\" lastpage=\"633\" xmlns...  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<casebody firstpage=\"260\" lastpage=\"262\" xmlns=\"http://nrs.harvard.edu/urn-3:HLS.Libr.US_Case_Law.Schema.Case_Body:v1\">\\n  <court id=\"b324-3\">SUPREME COURT,</court>\\n  <p id=\"b324-5\">RALEIGH, (N. C.)</p>\\n  <decisiondate id=\"Atf\">JULY, 1810.</decisiondate>\\n  <parties id=\"b324-6\"><em>The Stat</em>e vs. <em>John Owen</em>.</parties>\\n  <headnotes id=\"A8a\">Murder.</headnotes>\\n  <headnotes id=\"b324-4\">In an indictment for murder the length and depth of the wound must be expressed. 2 Hawk. b. 2, c. 33, § 81. 2 Chitty’s C. L. 488.</headnotes>\\n  <summary id=\"b324-9\">This case came oil to be argued before the supreme court on exceptions taken to the indictment in behalf of the prisoner. The exceptions were—That the mortal wounds alleged to have occasioned the death were pot <em>positively </em>alleged to have been given by the prisoner, but were only to be collected by intendment or implication; and that the length and depth of the wounds alleged were not described to be of any dimensions.</summary>\\n  <summary id=\"b324-10\">As to the first exception, the judges were unanimous that the wounds were laid to have been given by the prisoner with sufficient certainty, and of course overruled the objection : but as to the last, exception the judges were divided. Judge Taylor, who delivered his opinion, (and with which Judge Locke concurred,) remarked, that in all cases where the wound was charged to have been inflicted with a <em>blunt </em>instrument, such as a cudgel or a stick, the court would construe the word “ wound” to signify a bruise; and that inasmuch as it was admitted that in the case of a <em>bruise </em>the dimensions need not- be stated, therefore in his opinion it became useless in the indictment before the court. But Judges Hall, Lowrie, and Henderson held a contrary opinion.</summary>\\n  <summary id=\"b324-11\">It was by them stated, that in a case of this kind the court had <em>no </em>discretion.—It only became necessary to examine the law upon the subject, and to ascertain there<page-number citation-index=\"1\" label=\"261\">*261</page-number>by whether the indictment in question contained those requisites which the <em>law </em>had declared essentially necessary. That if they had been called upon to carve out a system of jurisprudence, whether they would have required such nicety and formality they were unprepared to determine. But being required to pass upon the law as it is written, they felt themselves imperiously bound to determine thereby, disregarding any of the consequences Which result from it. That authorities had been produced to the court from which it appeared that there was an uninterrupted chain of adjudication <em>expressly in point </em>from the earliest times to the present day : that in all cases of indictment for murder charged to have been committed by the giving of a wound, the nature and description of the wound should be set forth. That these authorities were fortified and supported by the books of precedents, which have <em>invariably </em>pursued this <em>nicety, </em>except in a very ancient collection compiled by West about two hundred years ago. That as to the cases from West, in which this formality is not observed, they were susceptible of this remark : that these precedents were in <em>Latin, </em>and that the words <em>“ mortalem </em>plagam” signified either a <em>mortal wound, </em>or <em>mortal bruise ; </em>but that in the case before the court the indictment was in the English language, and it had charged the murder to have been committed by a mortal <em>wound. </em>That at the time this country adopted the common law of England, (if the court were to regard authority,) this formality was required, and being so required by <em>law, </em>the court could not dispense with it.</summary>\\n  <opinion type=\"majority\">\\n    <p id=\"b325-4\">A majority of the court, therefore, being of the latter opinion, the bill of indictment was pronounced exceptionable: <page-number citation-index=\"1\" label=\"262\">*262</page-number>consequently, upon it sentence of death cannot bo passed , . <em>1 </em>upon the prisoner.</p>\\n    <p id=\"AqBH\">The keeper of the jail having received a mittimus to retain the prisoner, he will of course remain in jail until October term of the superior court, when a new bill will be drawn, and another trial will take place.</p>\\n  </opinion>\\n</casebody>\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# in this example casebody data we can see headnotes and opinions, such as majority.\n",
    "data['casebody.data'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['decision_date_p'] = pd.to_datetime(data.decision_date,errors='coerce')\n",
    "data['decision_year'] = data.decision_date_p.dt.year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We work with a smaller sample, of last 10 years (2008 to 2017). We do this because of computational resource limiations. Training and testing on this smaller sample takes a couple of hours even on large EC2 machines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2008 = data[data.decision_year>=2008]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenize Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data is tokenized using the Stanford Core NLP Library. (It's a java library and the setup instructions have been outlined above)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(raw_path,save_path):\n",
    "    stories_dir = os.path.abspath(raw_path)\n",
    "    tokenized_stories_dir = os.path.abspath(save_path)\n",
    "\n",
    "    print(\"Preparing to tokenize %s to %s...\" % (stories_dir, tokenized_stories_dir))\n",
    "    stories = os.listdir(stories_dir)\n",
    "    # make IO list file\n",
    "    print(\"Making list of files to tokenize...\")\n",
    "    with open(\"mapping_for_corenlp.txt\", \"w\") as f:\n",
    "        for s in stories:\n",
    "            f.write(\"%s\\n\" % (os.path.join(stories_dir, s)))\n",
    "    command = ['java', 'edu.stanford.nlp.pipeline.StanfordCoreNLP', '-annotators', 'tokenize,ssplit',\n",
    "               '-ssplit.newlineIsSentenceBreak', 'always', '-filelist', 'mapping_for_corenlp.txt', '-outputFormat',\n",
    "               'json', '-outputDirectory', tokenized_stories_dir]\n",
    "    print(\"Tokenizing %i files in %s and saving in %s...\" % (len(stories), stories_dir, tokenized_stories_dir))\n",
    "    subprocess.call(command)\n",
    "    print(\"Stanford CoreNLP Tokenizer has finished.\")\n",
    "    os.remove(\"mapping_for_corenlp.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a small sample dataset to test our initial code\n",
    "sample_data = data_2008.iloc[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we are extracting the majority opinion and headnotes from casebody.data.\n",
    "\n",
    "To prepare a robust training dataset, we selected cases with headnotes having a length of more that 150 and with majority opinions longer than the headnotes and we removed the return characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in data_2008.iterrows():\n",
    "    try:\n",
    "        caseid = row[1].id\n",
    "        markup = row[1]['casebody.data']\n",
    "        soup = BeautifulSoup(markup, \"xml\")\n",
    "        opinion = soup.find_all('opinion')[0]\n",
    "        opinion_text = opinion.getText()\n",
    "        opinion_text = opinion_text.encode(\"ascii\", \"ignore\").strip().decode(\"ascii\")\n",
    "        headnotes = (' '.join([headnotes.getText() for headnotes in soup.find_all('headnotes')])).replace('\\n', ' ')\n",
    "        headnotes = headnotes.encode(\"ascii\", \"ignore\").strip().decode(\"ascii\")\n",
    "\n",
    "        if (len(headnotes) > 150 and len(opinion_text)>len(headnotes)):\n",
    "            with open(f'presumm_data/parsed_text/opinions/{caseid}.txt','w') as f:\n",
    "                f.write(opinion_text)\n",
    "\n",
    "            with open(f'presumm_data/parsed_text/headnotes/{caseid}.txt','w') as f:\n",
    "                f.write(headnotes)\n",
    "    except:\n",
    "        print(f'Case ID {caseid} parsing failed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing to tokenize C:\\Users\\gufra\\OneDrive\\Documents\\Academics\\AdvancedTopicsInDataScience\\final_project\\presumm_data\\parsed_text\\opinions to C:\\Users\\gufra\\OneDrive\\Documents\\Academics\\AdvancedTopicsInDataScience\\final_project\\presumm_data\\tokenized_text\\opinions...\n",
      "Making list of files to tokenize...\n",
      "Tokenizing 3693 files in C:\\Users\\gufra\\OneDrive\\Documents\\Academics\\AdvancedTopicsInDataScience\\final_project\\presumm_data\\parsed_text\\opinions and saving in C:\\Users\\gufra\\OneDrive\\Documents\\Academics\\AdvancedTopicsInDataScience\\final_project\\presumm_data\\tokenized_text\\opinions...\n",
      "Stanford CoreNLP Tokenizer has finished.\n"
     ]
    }
   ],
   "source": [
    "# We are using the tokenizer function from the Stanford Core NLP Library for the PreSumm model\n",
    "# these are the opinions\n",
    "parsed_opinions_path = 'presumm_data/parsed_text/opinions'\n",
    "tokenized_opinions_path = 'presumm_data/tokenized_text/opinions'\n",
    "tokenize(parsed_opinions_path,tokenized_opinions_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing to tokenize C:\\Users\\gufra\\OneDrive\\Documents\\Academics\\AdvancedTopicsInDataScience\\final_project\\presumm_data\\parsed_text\\headnotes to C:\\Users\\gufra\\OneDrive\\Documents\\Academics\\AdvancedTopicsInDataScience\\final_project\\presumm_data\\tokenized_text\\headnotes...\n",
      "Making list of files to tokenize...\n",
      "Tokenizing 3693 files in C:\\Users\\gufra\\OneDrive\\Documents\\Academics\\AdvancedTopicsInDataScience\\final_project\\presumm_data\\parsed_text\\headnotes and saving in C:\\Users\\gufra\\OneDrive\\Documents\\Academics\\AdvancedTopicsInDataScience\\final_project\\presumm_data\\tokenized_text\\headnotes...\n",
      "Stanford CoreNLP Tokenizer has finished.\n"
     ]
    }
   ],
   "source": [
    "# Here we are tokenizing the headnotes\n",
    "parsed_headnotes_path = 'presumm_data/parsed_text/headnotes'\n",
    "tokenized_headnotes_path = 'presumm_data/tokenized_text/headnotes'\n",
    "tokenize(parsed_headnotes_path,tokenized_headnotes_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting to JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create functions to convert the tokenized opinions and headnotes JSON\n",
    "REMAP = {\"-lrb-\": \"(\", \"-rrb-\": \")\", \"-lcb-\": \"{\", \"-rcb-\": \"}\",\n",
    "         \"-lsb-\": \"[\", \"-rsb-\": \"]\", \"``\": '\"', \"''\": '\"'}\n",
    "\n",
    "\n",
    "def clean(x):\n",
    "    return re.sub(\n",
    "        r\"-lrb-|-rrb-|-lcb-|-rcb-|-lsb-|-rsb-|``|''\",\n",
    "        lambda m: REMAP.get(m.group()), x)\n",
    "\n",
    "def load_json(case_id):\n",
    "    source = []\n",
    "    tgt = []\n",
    "    source_path = os.path.join('presumm_data/tokenized_text/opinions',f'{case_id}.txt.json')\n",
    "    target_path = os.path.join('presumm_data/tokenized_text/headnotes',f'{case_id}.txt.json')\n",
    "    for sent in json.load(open(source_path,encoding='utf-8'))['sentences']:\n",
    "        tokens = [t['word'].encode(\"ascii\", \"ignore\").strip().decode(\"utf-8\") for t in sent['tokens']]\n",
    "        tokens = [t.lower() for t in tokens]\n",
    "        source.append(tokens)\n",
    "    for sent in json.load(open(target_path,encoding='utf-8'))['sentences']:\n",
    "        tokens = [t['word'].encode(\"ascii\", \"ignore\").strip().decode(\"utf-8\") for t in sent['tokens']]\n",
    "        tokens = [t.lower() for t in tokens]\n",
    "        tgt.append(tokens)\n",
    "\n",
    "\n",
    "    source = [clean(' '.join(sent)).split() for sent in source]\n",
    "    tgt = [clean(' '.join(sent)).split() for sent in tgt]\n",
    "    return source, tgt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Greedy Selection\n",
    "\n",
    "A greedy algorithm is any algorithm that makes the locally optimal choice at each stage with the intent of finding a global optimum. In many problems, a greedy strategy does not usually produce an optimal solution, but may yield a locally optimal solutions.\n",
    "\n",
    "Here we use this type of selection to extract sentences from the opinion that closely matches sentences in the headnotes, using a ROUGE score matrix to make that decision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create function to extract opinion sentence to generate a summary similar to the headnotes\n",
    "import re\n",
    "\n",
    "def _get_ngrams(n, text):\n",
    "    \"\"\"Calcualtes n-grams.\n",
    "\n",
    "    Args:\n",
    "      n: which n-grams to calculate\n",
    "      text: An array of tokens\n",
    "\n",
    "    Returns:\n",
    "      A set of n-grams\n",
    "    \"\"\"\n",
    "    ngram_set = set()\n",
    "    text_length = len(text)\n",
    "    max_index_ngram_start = text_length - n\n",
    "    for i in range(max_index_ngram_start + 1):\n",
    "        ngram_set.add(tuple(text[i:i + n]))\n",
    "    return ngram_set\n",
    "\n",
    "\n",
    "def _get_word_ngrams(n, sentences):\n",
    "    \"\"\"Calculates word n-grams for multiple sentences.\n",
    "    \"\"\"\n",
    "    assert len(sentences) > 0\n",
    "    assert n > 0\n",
    "\n",
    "    # words = _split_into_words(sentences)\n",
    "\n",
    "    words = sum(sentences, [])\n",
    "    # words = [w for w in words if w not in stopwords]\n",
    "    return _get_ngrams(n, words)\n",
    "\n",
    "\n",
    "def cal_rouge(evaluated_ngrams, reference_ngrams):\n",
    "    reference_count = len(reference_ngrams)\n",
    "    evaluated_count = len(evaluated_ngrams)\n",
    "\n",
    "    overlapping_ngrams = evaluated_ngrams.intersection(reference_ngrams)\n",
    "    overlapping_count = len(overlapping_ngrams)\n",
    "\n",
    "    if evaluated_count == 0:\n",
    "        precision = 0.0\n",
    "    else:\n",
    "        precision = overlapping_count / evaluated_count\n",
    "\n",
    "    if reference_count == 0:\n",
    "        recall = 0.0\n",
    "    else:\n",
    "        recall = overlapping_count / reference_count\n",
    "\n",
    "    f1_score = 2.0 * ((precision * recall) / (precision + recall + 1e-8))\n",
    "    return {\"f\": f1_score, \"p\": precision, \"r\": recall}\n",
    "\n",
    "\n",
    "def greedy_selection(doc_sent_list, abstract_sent_list, summary_size):\n",
    "    def _rouge_clean(s):\n",
    "        return re.sub(r'[^a-zA-Z0-9 ]', '', s)\n",
    "   \n",
    "    max_rouge = 0.0\n",
    "    abstract = sum(abstract_sent_list, [])\n",
    "    #abstract = abstract_sent_list\n",
    "    abstract = _rouge_clean(' '.join(abstract)).split()\n",
    "    sents = [_rouge_clean(' '.join(s)).split() for s in doc_sent_list]\n",
    "    evaluated_1grams = [_get_word_ngrams(1, [sent]) for sent in sents]\n",
    "    #print(evaluated_1grams)\n",
    "    reference_1grams = _get_word_ngrams(1, [abstract])\n",
    "    evaluated_2grams = [_get_word_ngrams(2, [sent]) for sent in sents]\n",
    "    reference_2grams = _get_word_ngrams(2, [abstract])\n",
    "\n",
    "    selected = []\n",
    "\n",
    "    for s in range(summary_size):\n",
    "        cur_max_rouge = max_rouge\n",
    "        cur_id = -1\n",
    "        \n",
    "        for i in range(len(sents)):\n",
    "            if (i in selected):\n",
    "                continue\n",
    "                \n",
    "            c = selected + [i]\n",
    "            candidates_1 = [evaluated_1grams[idx] for idx in c]\n",
    "            candidates_1 = set.union(*map(set, candidates_1))\n",
    "            candidates_2 = [evaluated_2grams[idx] for idx in c]\n",
    "            candidates_2 = set.union(*map(set, candidates_2))\n",
    "            rouge_1 = cal_rouge(candidates_1, reference_1grams)['f']\n",
    "            rouge_2 = cal_rouge(candidates_2, reference_2grams)['f']\n",
    "            rouge_score = rouge_1 + rouge_2           \n",
    "            if rouge_score > cur_max_rouge:\n",
    "                cur_max_rouge = rouge_score\n",
    "                cur_id = i\n",
    "        if (cur_id == -1):\n",
    "            return sorted(selected)\n",
    "        selected.append(cur_id)\n",
    "        max_rouge = cur_max_rouge\n",
    "    \n",
    "    \n",
    "    return sorted(selected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bert Data\n",
    "\n",
    "We use the Bert pre-processing function to prepare the data. Here we define the function necessary to acheive that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_src_nsents =10000\n",
    "class BertData():\n",
    "    def __init__(self, min_src_ntokens_per_sent=5,\n",
    "                max_src_ntokens_per_sent=200,\n",
    "                max_src_nsents=max_src_nsents,\n",
    "                min_src_nsents=1,\n",
    "                max_tgt_ntokens=500,\n",
    "                min_tgt_ntokens=5):\n",
    "        self.min_src_ntokens_per_sent = min_src_ntokens_per_sent\n",
    "        self.max_src_ntokens_per_sent = max_src_ntokens_per_sent\n",
    "        self.max_src_nsents = max_src_nsents\n",
    "        self.min_src_nsents = min_src_nsents\n",
    "        self.max_tgt_ntokens = max_tgt_ntokens\n",
    "        self.min_tgt_ntokens = min_tgt_ntokens\n",
    "        self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "\n",
    "        self.sep_token = '[SEP]'\n",
    "        self.cls_token = '[CLS]'\n",
    "        self.pad_token = '[PAD]'\n",
    "        self.tgt_bos = '[unused0]'\n",
    "        self.tgt_eos = '[unused1]'\n",
    "        self.tgt_sent_split = '[unused2]'\n",
    "        self.sep_vid = self.tokenizer.vocab[self.sep_token]\n",
    "        self.cls_vid = self.tokenizer.vocab[self.cls_token]\n",
    "        self.pad_vid = self.tokenizer.vocab[self.pad_token]\n",
    "\n",
    "    def preprocess(self, src, tgt, sent_labels, use_bert_basic_tokenizer=False, is_test=False):\n",
    "\n",
    "        if ((not is_test) and len(src) == 0):\n",
    "            return None\n",
    "\n",
    "        original_src_txt = [' '.join(s) for s in src]\n",
    "\n",
    "        idxs = [i for i, s in enumerate(src) if (len(s) > self.min_src_ntokens_per_sent)]\n",
    "\n",
    "        _sent_labels = [0] * len(src)\n",
    "        for l in sent_labels:\n",
    "            _sent_labels[l] = 1\n",
    "\n",
    "        src = [src[i][:self.max_src_ntokens_per_sent] for i in idxs]\n",
    "        sent_labels = [_sent_labels[i] for i in idxs]\n",
    "        src = src[:self.max_src_nsents]\n",
    "        sent_labels = sent_labels[:self.max_src_nsents]\n",
    "\n",
    "        if ((not is_test) and len(src) < self.min_src_nsents):\n",
    "            return None\n",
    "\n",
    "        src_txt = [' '.join(sent) for sent in src]\n",
    "        text = ' {} {} '.format(self.sep_token, self.cls_token).join(src_txt)\n",
    "\n",
    "        src_subtokens = self.tokenizer.tokenize(text)\n",
    "\n",
    "        src_subtokens = [self.cls_token] + src_subtokens + [self.sep_token]\n",
    "        src_subtoken_idxs = self.tokenizer.convert_tokens_to_ids(src_subtokens)\n",
    "        _segs = [-1] + [i for i, t in enumerate(src_subtoken_idxs) if t == self.sep_vid]\n",
    "        segs = [_segs[i] - _segs[i - 1] for i in range(1, len(_segs))]\n",
    "        segments_ids = []\n",
    "        for i, s in enumerate(segs):\n",
    "            if (i % 2 == 0):\n",
    "                segments_ids += s * [0]\n",
    "            else:\n",
    "                segments_ids += s * [1]\n",
    "        cls_ids = [i for i, t in enumerate(src_subtoken_idxs) if t == self.cls_vid]\n",
    "        sent_labels = sent_labels[:len(cls_ids)]\n",
    "\n",
    "        tgt_subtokens_str = '[unused0] ' + ' [unused2] '.join(\n",
    "            [' '.join(self.tokenizer.tokenize(' '.join(tt), use_bert_basic_tokenizer=use_bert_basic_tokenizer)) for tt in tgt]) + ' [unused1]'\n",
    "        tgt_subtoken = tgt_subtokens_str.split()[:self.max_tgt_ntokens]\n",
    "        if ((not is_test) and len(tgt_subtoken) < self.min_tgt_ntokens):\n",
    "            return None\n",
    "\n",
    "        tgt_subtoken_idxs = self.tokenizer.convert_tokens_to_ids(tgt_subtoken)\n",
    "\n",
    "        tgt_txt = '<q>'.join([' '.join(tt) for tt in tgt])\n",
    "        src_txt = [original_src_txt[i] for i in idxs]\n",
    "\n",
    "        return src_subtoken_idxs, sent_labels, tgt_subtoken_idxs, segments_ids, cls_ids, src_txt, tgt_txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3693"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# here we are extracting the case IDs from the tokenized opinions\n",
    "case_files = os.listdir('./presumm_data/tokenized_text/opinions')\n",
    "case_ids = [case_file.replace(\".txt.json\",\"\") for case_file in case_files]\n",
    "parsed_files = [case_id.replace(\".json\",\"\") for case_id in os.listdir('./presumm_data/json_data')]\n",
    "#case_ids = list(set(case_ids).difference(parsed_files))\n",
    "len(case_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a frunction to generate the labels for the sentences for each case opinion\n",
    "def generate_bert_data(case_id):\n",
    "    source, tgt = load_json(case_id)\n",
    "    sent_labels = greedy_selection(source[:max_src_nsents], tgt, 5)\n",
    "    source = [' '.join(s).lower().split() for s in source]\n",
    "    tgt = [' '.join(s).lower().split() for s in tgt]\n",
    "    bert = BertData()\n",
    "    b_data = bert.preprocess(source, tgt, sent_labels, use_bert_basic_tokenizer=True,\n",
    "                                     is_test=False)\n",
    "    if b_data is not None:\n",
    "        src_subtoken_idxs, sent_labels, tgt_subtoken_idxs, segments_ids, cls_ids, src_txt, tgt_txt = b_data\n",
    "        b_data_dict = {\"src\": src_subtoken_idxs, \"tgt\": tgt_subtoken_idxs,\n",
    "                               \"src_sent_labels\": sent_labels, \"segs\": segments_ids, 'clss': cls_ids,\n",
    "                               'src_txt': src_txt, \"tgt_txt\": tgt_txt}\n",
    "        return (case_id,b_data_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mutliprocessing_funcs import generate_bert_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting the data into JSON\n",
    "from multiprocessing import Pool\n",
    "pool = Pool(32)\n",
    "for b_data_tp in pool.imap_unordered(generate_bert_data,case_ids):\n",
    "    if b_data_tp is not None:\n",
    "        with open(f'./presumm_data/json_data/{b_data_tp[0]}.json', 'w') as fp:\n",
    "            json.dump(b_data_tp[1], fp)\n",
    "pool.close()\n",
    "pool.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Train, test and validation datasets\n",
    "We are spliting the data into the train, test, and validation sets using 80%, 10%, and 10% of the data, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cases = [case_id.replace(\".json\",\"\") for case_id in os.listdir('./presumm_data/json_data/')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cases = len(all_cases)\n",
    "train_cases = int(np.ceil(num_cases*0.8))\n",
    "val_cases = int(np.ceil((num_cases-train_cases)/2))\n",
    "test_cases = num_cases-val_cases-train_cases\n",
    "all_index = np.arange(num_cases)\n",
    "np.random.seed(1)\n",
    "np.random.shuffle(all_index)\n",
    "train_indices =all_index[:train_cases]\n",
    "val_indices = all_index[train_cases:train_cases+val_cases]\n",
    "test_indices = all_index[train_cases+val_cases:] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cases = np.array(all_cases)[train_indices]\n",
    "val_cases = np.array(all_cases)[val_indices]\n",
    "test_cases = np.array(all_cases)[test_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_samples(case_list):\n",
    "    appended_samples = []\n",
    "    for case_id in case_list:\n",
    "        try:\n",
    "            with open(f'./presumm_data/json_data/{case_id}.json','r') as f:\n",
    "                case_content = f.read()\n",
    "                case_content = json.loads(case_content)\n",
    "            appended_samples.append(case_content)\n",
    "        except:\n",
    "            print(f'Error reading case {case_id}')\n",
    "    return appended_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = append_samples(train_cases)\n",
    "val_dataset = append_samples(val_cases)\n",
    "test_dataset = append_samples(test_cases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(train_dataset, 'presumm_data/train_dataset.pt')\n",
    "torch.save(val_dataset, 'presumm_data/val_dataset.pt')\n",
    "torch.save(test_dataset, 'presumm_data/test_dataset.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sample_dataset = append_samples(test_cases[:10])\n",
    "len(test_sample_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(test_sample_dataset, 'presumm/bert_data/sample/cnndm.test.1.bert.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('test_cases.json','w') as f:\n",
    "    json.dump(test_cases.tolist(),f)\n",
    "\n",
    "with open('train_cases.json','w') as f:\n",
    "    json.dump(train_cases.tolist(),f)\n",
    "\n",
    "with open('val_cases.json','w') as f:\n",
    "    json.dump(val_cases.tolist(),f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Prep for MatchSum data\n",
    "\n",
    "We are using the Greedy Selection functon to extract sentences and labeling them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Match Sum Data\n",
    "with open('test_cases.json','r') as f:\n",
    "    test_cases = json.load(f)\n",
    "\n",
    "text_summary=[]\n",
    "sent_id = []\n",
    "\n",
    "for case_id in test_cases:\n",
    "    \n",
    "    source, tgt = load_json(case_id)\n",
    "    sent_labels = greedy_selection(source[:max_src_nsents], tgt, 5)\n",
    "    source = [' '.join(s).lower() for s in source]\n",
    "    tgt = [' '.join(s).lower() for s in tgt]\n",
    "    #text_summary.append({'text':source, 'summary':tgt})\n",
    "    #sent_id.append({'sent_id':sent_labels})\n",
    "\n",
    "    with open('sentence_id.json','a+') as f:\n",
    "        json.dump({'sent_id':sent_labels},f)\n",
    "        f.write('\\n')\n",
    "    \n",
    "    with open('match_summ_sample.json','a+') as f:\n",
    "        json.dump({'text':source, 'summary':tgt},f)\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:.1px solid grey\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='presumm'></a>\n",
    "# Pre-Summ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Source**:\n",
    "\n",
    "Code: https://github.com/nlpyang/PreSumm/\n",
    "\n",
    "\n",
    "Paper: https://arxiv.org/abs/1908.08345\n",
    "\n",
    "Description:\n",
    "\n",
    "The PreSumm modle uses BERT for text summarization and propose a general framework for extractive models. This is a document-level encoder based on BERT which is able to express the semantics of a document and obtain representations for its sentences. Several inter-sentence transformer layers are stacked over the BERT encoder. This model produces extraction based summaries\n",
    "This model can also produce abstraction based summary. This model uses new fine-tuning schedule adopting different optimizers for the encoder and the decoder as a means of alleviating the mismatch between the two (the former is pretrained while the latter is not).  It takes as input the summaries provided by the extraction based model.\n",
    "\n",
    "\n",
    "Environment setup script - https://github.com/gufranpathan/case_law_g45/blob/master/presum_env_setup.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-requisities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Libraries**: \n",
    "\n",
    "Torch 1.1.0 (download instructions from https://pytorch.org/get-started/previous-versions/)\n",
    "\n",
    "`pip install pytorch-transformers tensorboardX pyrouge`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Rouge** \n",
    "\n",
    "Rouge is a perl library that is used commonly for metric calculation. The environment setup script referenced above should create the environment for Rouge as well. For further details please see - https://github.com/andersjo/pyrouge/tree/master/tools/ROUGE-1.5.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter Declaration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import Namespace\n",
    "from train_abstractive import test_abs,train_abs_single\n",
    "from train_extractive import test_ext,train_single_ext\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paramenters needed to run the PreSumm model\n",
    "# using the defaults for all parameters\n",
    "arg_params = {'accum_count':1,\n",
    "'alpha':0.6,\n",
    "'batch_size':300,\n",
    "'beam_size':5,\n",
    "'beta1':0.9,\n",
    "'beta2':0.999,\n",
    "'block_trigram':True,\n",
    "'dec_dropout':0.2,\n",
    "'dec_ff_size':2048,\n",
    "'dec_heads':8,\n",
    "'dec_hidden_size':768,\n",
    "'dec_layers':6,\n",
    "'enc_dropout':0.2,\n",
    "'enc_ff_size':512,\n",
    "'enc_hidden_size':512,\n",
    "'enc_layers':6,\n",
    "'encoder':'bert',\n",
    "'ext_dropout':0.2,\n",
    "'ext_ff_size':2048,\n",
    "'ext_heads':8,\n",
    "'ext_hidden_size':768,\n",
    "'ext_layers':2,\n",
    "'finetune_bert':True,\n",
    "'generator_shard_size':32,\n",
    "'gpu_ranks':[0],\n",
    "'label_smoothing':0.1,\n",
    "'large':False,\n",
    "'load_from_extractive':'',\n",
    "'lr':1,\n",
    "'lr_bert':0.002,\n",
    "'lr_dec':0.002,\n",
    "'max_grad_norm':0,\n",
    "'max_length':150,\n",
    "'max_pos':512,\n",
    "'max_tgt_len':140,\n",
    "'min_length':15,\n",
    "'optim':'adam',\n",
    "'param_init':0,\n",
    "'param_init_glorot':True,\n",
    "'recall_eval':False,\n",
    "'report_every':1,\n",
    "'report_rouge':True,\n",
    "'save_checkpoint_steps':15,\n",
    "'seed':666,\n",
    "'sep_optim':False,\n",
    "'share_emb':False,\n",
    "'temp_dir':'./temp',\n",
    "'test_all':False,\n",
    "'test_batch_size':200,\n",
    "'test_start_from':-1,\n",
    "'train_from':'',\n",
    "'train_steps':1000,\n",
    "'use_bert_emb':False,\n",
    "'use_interval':True,\n",
    "'visible_gpus':'-1',\n",
    "'warmup_steps':8000,\n",
    "'warmup_steps_bert':8000,\n",
    "'warmup_steps_dec':8000,\n",
    "'world_size':1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='pretrained_presum'></a>\n",
    "## Baseline Evaluation (Pre-tained model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extractive Summarization\n",
    "\n",
    "Using the pre-trained model we are generating extractive summarization using the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ext_args_dict = arg_params\n",
    "ext_args_dict.update({\n",
    "            'bert_data_path':'./data',\n",
    "    'log_file':'./logs/ext_baseline',\n",
    "    'model_path':'./model_files/pre_trained/ext',\n",
    "    'result_path':'./results/pre_trained/ext_baseline',\n",
    "    'test_from':'./model_files/pre_trained/ext/bertext_cnndm_transformer.pt',\n",
    "    'task':'ext',\n",
    "    'mode':'test',\n",
    "\n",
    "    'batch_size':300,\n",
    "    'ext_dropout':0.1\n",
    "})\n",
    "\n",
    "args = Namespace(**ext_args_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 433/433 [00:00<00:00, 349659.92B/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(accum_count=1, alpha=0.6, batch_size=300, beam_size=5, bert_data_path='./data', beta1=0.9, beta2=0.999, block_trigram=True, dec_dropout=0.2, dec_ff_size=2048, dec_heads=8, dec_hidden_size=768, dec_layers=6, enc_dropout=0.2, enc_ff_size=512, enc_hidden_size=512, enc_layers=6, encoder='bert', ext_dropout=0.1, ext_ff_size=2048, ext_heads=8, ext_hidden_size=768, ext_layers=2, finetune_bert=True, generator_shard_size=32, gpu_ranks=[0], label_smoothing=0.1, large=False, load_from_extractive='', log_file='./logs/ext_baseline', lr=1, lr_bert=0.002, lr_dec=0.002, max_grad_norm=0, max_length=150, max_pos=512, max_tgt_len=140, min_length=15, mode='test', model_path='./model_files/pre_trained/ext', optim='adam', param_init=0, param_init_glorot=True, recall_eval=False, report_every=1, report_rouge=True, result_path='./results/pre_trained/ext_baseline', save_checkpoint_steps=15, seed=666, sep_optim=False, share_emb=False, task='ext', temp_dir='./temp', test_all=False, test_batch_size=200, test_from='./model_files/pre_trained/ext/bertext_cnndm_transformer.pt', test_start_from=-1, train_from='', train_steps=1000, use_bert_emb=False, use_interval=True, visible_gpus='-1', warmup_steps=8000, warmup_steps_bert=8000, warmup_steps_dec=8000, world_size=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 440473133/440473133 [00:09<00:00, 45928011.17B/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pts ['./data/test.pt']\n",
      "gpu_rank 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-05-09 17:26:44,770 [MainThread  ] [INFO ]  Writing summaries.\n",
      "2020-05-09 17:26:44,772 [MainThread  ] [INFO ]  Processing summaries. Saving system files to ./temp/tmptfgzu6h4/system and model files to ./temp/tmptfgzu6h4/model.\n",
      "2020-05-09 17:26:44,772 [MainThread  ] [INFO ]  Processing files in ./temp/rouge-tmp-2020-05-09-17-26-44/candidate/.\n",
      "2020-05-09 17:26:44,815 [MainThread  ] [INFO ]  Saved processed files to ./temp/tmptfgzu6h4/system.\n",
      "2020-05-09 17:26:44,816 [MainThread  ] [INFO ]  Processing files in ./temp/rouge-tmp-2020-05-09-17-26-44/reference/.\n",
      "2020-05-09 17:26:44,864 [MainThread  ] [INFO ]  Saved processed files to ./temp/tmptfgzu6h4/model.\n",
      "2020-05-09 17:26:44,869 [MainThread  ] [INFO ]  Written ROUGE configuration to ./temp/tmpitnfnofj/rouge_conf.xml\n",
      "2020-05-09 17:26:44,869 [MainThread  ] [INFO ]  Running ROUGE with command perl ./ROUGE-1.5.5/ROUGE-1.5.5.pl -e ./ROUGE-1.5.5/data -c 95 -m -r 1000 -n 2 -a ./temp/tmpitnfnofj/rouge_conf.xml\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "369\n",
      "369\n",
      "---------------------------------------------\n",
      "1 ROUGE-1 Average_R: 0.24577 (95%-conf.int. 0.23134 - 0.26120)\n",
      "1 ROUGE-1 Average_P: 0.49301 (95%-conf.int. 0.47854 - 0.50676)\n",
      "1 ROUGE-1 Average_F: 0.29475 (95%-conf.int. 0.28252 - 0.30729)\n",
      "---------------------------------------------\n",
      "1 ROUGE-2 Average_R: 0.09804 (95%-conf.int. 0.08843 - 0.10867)\n",
      "1 ROUGE-2 Average_P: 0.18863 (95%-conf.int. 0.17645 - 0.20073)\n",
      "1 ROUGE-2 Average_F: 0.11580 (95%-conf.int. 0.10651 - 0.12531)\n",
      "---------------------------------------------\n",
      "1 ROUGE-L Average_R: 0.20960 (95%-conf.int. 0.19742 - 0.22252)\n",
      "1 ROUGE-L Average_P: 0.42895 (95%-conf.int. 0.41545 - 0.44275)\n",
      "1 ROUGE-L Average_F: 0.25311 (95%-conf.int. 0.24279 - 0.26383)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generating and scoring the extractive summaries\n",
    "test_ext(args, device_id=-1, pt=args.test_from, step=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Abstractive Summarization (Bert)\n",
    "\n",
    "Using the pre-trained model we are generating abstractive summarization using the Bert model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "abs_args_dict = arg_params\n",
    "\n",
    "abs_args_dict.update({\n",
    "            'bert_data_path':'./data',\n",
    "    'log_file':'./logs/abs_bertextabs',\n",
    "    'model_path':'./model_files/pre_trained/abs_bertextabs/',\n",
    "    'result_path':'./results/pre_trained/abs_bertextabs',\n",
    "    'test_from':'./model_files/pre_trained/abs_bertextabs/model_step_148000.pt',\n",
    "    'task':'abs',\n",
    "    'mode':'test',\n",
    "    \n",
    "    'batch_size':300,\n",
    "    'test_batch_size':200,\n",
    "    'max_pos':512,\n",
    "    'max_length':200,\n",
    "    'alpha': 0.95,\n",
    "    'min_length':50,\n",
    "        \n",
    "    'sep_optim':True,\n",
    "    'user_interval':True\n",
    "\n",
    "})\n",
    "\n",
    "\n",
    "args = Namespace(**abs_args_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(accum_count=1, alpha=0.95, batch_size=300, beam_size=5, bert_data_path='./data', beta1=0.9, beta2=0.999, block_trigram=True, dec_dropout=0.2, dec_ff_size=2048, dec_heads=8, dec_hidden_size=768, dec_layers=6, enc_dropout=0.2, enc_ff_size=512, enc_hidden_size=512, enc_layers=6, encoder='bert', ext_dropout=0.1, ext_ff_size=2048, ext_heads=8, ext_hidden_size=768, ext_layers=2, finetune_bert=True, generator_shard_size=32, gpu_ranks=[0], label_smoothing=0.1, large=False, load_from_extractive='', log_file='./logs/abs_bertextabs', lr=1, lr_bert=0.002, lr_dec=0.002, max_grad_norm=0, max_length=200, max_pos=512, max_tgt_len=140, min_length=50, mode='test', model_path='./model_files/pre_trained/abs_bertextabs/', optim='adam', param_init=0, param_init_glorot=True, recall_eval=False, report_every=1, report_rouge=True, result_path='./results/pre_trained/abs_bertextabs', save_checkpoint_steps=15, seed=666, sep_optim=True, share_emb=False, task='abs', temp_dir='./temp', test_all=False, test_batch_size=200, test_from='./model_files/pre_trained/abs_bertextabs/model_step_148000.pt', test_start_from=-1, train_from='', train_steps=1000, use_bert_emb=False, use_interval=True, user_interval=True, visible_gpus='-1', warmup_steps=8000, warmup_steps_bert=8000, warmup_steps_dec=8000, world_size=1)\n",
      "pts ['./data/test.pt']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 231508/231508 [00:00<00:00, 6099608.21B/s]\n",
      "2020-05-09 18:29:11,656 [MainThread  ] [INFO ]  Writing summaries.\n",
      "2020-05-09 18:29:11,658 [MainThread  ] [INFO ]  Processing summaries. Saving system files to ./temp/tmpltn13h9f/system and model files to ./temp/tmpltn13h9f/model.\n",
      "2020-05-09 18:29:11,658 [MainThread  ] [INFO ]  Processing files in ./temp/rouge-tmp-2020-05-09-18-29-11/candidate/.\n",
      "2020-05-09 18:29:11,704 [MainThread  ] [INFO ]  Saved processed files to ./temp/tmpltn13h9f/system.\n",
      "2020-05-09 18:29:11,705 [MainThread  ] [INFO ]  Processing files in ./temp/rouge-tmp-2020-05-09-18-29-11/reference/.\n",
      "2020-05-09 18:29:11,757 [MainThread  ] [INFO ]  Saved processed files to ./temp/tmpltn13h9f/model.\n",
      "2020-05-09 18:29:11,762 [MainThread  ] [INFO ]  Written ROUGE configuration to ./temp/tmp1t6jzo0o/rouge_conf.xml\n",
      "2020-05-09 18:29:11,763 [MainThread  ] [INFO ]  Running ROUGE with command perl ./ROUGE-1.5.5/ROUGE-1.5.5.pl -e ./ROUGE-1.5.5/data -c 95 -m -r 1000 -n 2 -a ./temp/tmp1t6jzo0o/rouge_conf.xml\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "369\n",
      "369\n",
      "---------------------------------------------\n",
      "1 ROUGE-1 Average_R: 0.19541 (95%-conf.int. 0.18399 - 0.20711)\n",
      "1 ROUGE-1 Average_P: 0.45892 (95%-conf.int. 0.44256 - 0.47679)\n",
      "1 ROUGE-1 Average_F: 0.24623 (95%-conf.int. 0.23525 - 0.25664)\n",
      "---------------------------------------------\n",
      "1 ROUGE-2 Average_R: 0.06171 (95%-conf.int. 0.05450 - 0.06911)\n",
      "1 ROUGE-2 Average_P: 0.14881 (95%-conf.int. 0.13608 - 0.16175)\n",
      "1 ROUGE-2 Average_F: 0.07836 (95%-conf.int. 0.07054 - 0.08633)\n",
      "---------------------------------------------\n",
      "1 ROUGE-L Average_R: 0.16693 (95%-conf.int. 0.15691 - 0.17709)\n",
      "1 ROUGE-L Average_P: 0.40175 (95%-conf.int. 0.38643 - 0.41851)\n",
      "1 ROUGE-L Average_F: 0.21218 (95%-conf.int. 0.20277 - 0.22168)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generating and scoring the abstractive summaries\n",
    "test_abs(args, device_id=-1, pt=args.test_from, step=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Abstractive Summarization (Transformers)\n",
    "\n",
    "Using the pre-trained model we are generating abstractive summarization using the Transformers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(accum_count=1, alpha=0.95, batch_size=300, beam_size=5, bert_data_path='./data', beta1=0.9, beta2=0.999, block_trigram=True, dec_dropout=0.2, dec_ff_size=2048, dec_heads=8, dec_hidden_size=512, dec_layers=6, enc_dropout=0.2, enc_ff_size=2048, enc_hidden_size=512, enc_layers=6, encoder='baseline', ext_dropout=0.1, ext_ff_size=2048, ext_heads=8, ext_hidden_size=768, ext_layers=2, finetune_bert=True, generator_shard_size=32, gpu_ranks=[0], label_smoothing=0.1, large=False, load_from_extractive='', log_file='./logs/abs_transformers', lr=1, lr_bert=0.002, lr_dec=0.002, max_grad_norm=0, max_length=200, max_pos=512, max_tgt_len=140, min_length=50, mode='test', model_path='./model_files/pre_trained/abs_transformer/', optim='adam', param_init=0, param_init_glorot=True, recall_eval=False, report_every=1, report_rouge=True, result_path='./results/pre_trained/abs_transformer', save_checkpoint_steps=15, seed=666, sep_optim=False, share_emb=False, task='abs', temp_dir='./temp', test_all=False, test_batch_size=200, test_from='./model_files/pre_trained/abs_transformer/cnndm_baseline_best.pt', test_start_from=-1, train_from='', train_steps=1000, use_bert_emb=False, use_interval=True, user_interval=True, visible_gpus='-1', warmup_steps=8000, warmup_steps_bert=8000, warmup_steps_dec=8000, world_size=1)\n",
      "pts ['./data/test.pt']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-05-09 19:21:23,479 [MainThread  ] [INFO ]  Writing summaries.\n",
      "2020-05-09 19:21:23,480 [MainThread  ] [INFO ]  Processing summaries. Saving system files to ./temp/tmp1j8r5osy/system and model files to ./temp/tmp1j8r5osy/model.\n",
      "2020-05-09 19:21:23,481 [MainThread  ] [INFO ]  Processing files in ./temp/rouge-tmp-2020-05-09-19-21-23/candidate/.\n",
      "2020-05-09 19:21:23,527 [MainThread  ] [INFO ]  Saved processed files to ./temp/tmp1j8r5osy/system.\n",
      "2020-05-09 19:21:23,528 [MainThread  ] [INFO ]  Processing files in ./temp/rouge-tmp-2020-05-09-19-21-23/reference/.\n",
      "2020-05-09 19:21:23,582 [MainThread  ] [INFO ]  Saved processed files to ./temp/tmp1j8r5osy/model.\n",
      "2020-05-09 19:21:23,587 [MainThread  ] [INFO ]  Written ROUGE configuration to ./temp/tmpgfavjhyn/rouge_conf.xml\n",
      "2020-05-09 19:21:23,588 [MainThread  ] [INFO ]  Running ROUGE with command perl ./ROUGE-1.5.5/ROUGE-1.5.5.pl -e ./ROUGE-1.5.5/data -c 95 -m -r 1000 -n 2 -a ./temp/tmpgfavjhyn/rouge_conf.xml\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "369\n",
      "369\n",
      "---------------------------------------------\n",
      "1 ROUGE-1 Average_R: 0.20233 (95%-conf.int. 0.19042 - 0.21442)\n",
      "1 ROUGE-1 Average_P: 0.44334 (95%-conf.int. 0.42921 - 0.45924)\n",
      "1 ROUGE-1 Average_F: 0.24971 (95%-conf.int. 0.23907 - 0.26005)\n",
      "---------------------------------------------\n",
      "1 ROUGE-2 Average_R: 0.06280 (95%-conf.int. 0.05640 - 0.07004)\n",
      "1 ROUGE-2 Average_P: 0.13759 (95%-conf.int. 0.12712 - 0.14869)\n",
      "1 ROUGE-2 Average_F: 0.07703 (95%-conf.int. 0.07082 - 0.08388)\n",
      "---------------------------------------------\n",
      "1 ROUGE-L Average_R: 0.17118 (95%-conf.int. 0.16133 - 0.18091)\n",
      "1 ROUGE-L Average_P: 0.38531 (95%-conf.int. 0.37209 - 0.40006)\n",
      "1 ROUGE-L Average_F: 0.21326 (95%-conf.int. 0.20432 - 0.22181)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "abs_args_dict = arg_params\n",
    "\n",
    "abs_args_dict.update({\n",
    "            'bert_data_path':'./data',\n",
    "    'log_file':'./logs/abs_transformers',\n",
    "    'model_path':'./model_files/pre_trained/abs_transformer/',\n",
    "    'result_path':'./results/pre_trained/abs_transformer',\n",
    "    'test_from':'./model_files/pre_trained/abs_transformer/cnndm_baseline_best.pt',\n",
    "    'task':'abs',\n",
    "    'mode':'test',\n",
    "    \n",
    "    'batch_size':300,\n",
    "    'test_batch_size':200,\n",
    "    'max_pos':512,\n",
    "    'max_length':200,\n",
    "    'min_length':50,\n",
    "        \n",
    "    'sep_optim':False,\n",
    "\n",
    "})\n",
    "\n",
    "\n",
    "args = Namespace(**abs_args_dict)\n",
    "# Generating and scoring the abstractive summaries\n",
    "test_abs(args, device_id=-1, pt=args.test_from, step=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='trained_presum'></a>\n",
    "## Training & Evaluation on Case Law Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extractive Summarization\n",
    "\n",
    "Traning the model to generate extractive summarization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_steps = 30\n",
    "ext_args_train_dict = arg_params\n",
    "\n",
    "ext_args_train_dict.update({\n",
    "    \n",
    "            'bert_data_path':'./data',\n",
    "    'log_file':'./logs/train_ext',\n",
    "    'mode':'train',\n",
    "    'model_path':'./model_files/trained/ext',\n",
    "    'result_path':'../results/trained/ext',\n",
    "    'train_from':'./model_files/pre_trained/ext/bertext_cnndm_transformer.pt',\n",
    "\n",
    "    'report_every':1,\n",
    "    'save_checkpoint_steps':15,\n",
    "    'batch_size':300,\n",
    "    'train_steps':18001 + training_steps,\n",
    "    'warmup_steps':1,\n",
    "    'max_pos':512,\n",
    "\n",
    "    'task':'ext',\n",
    "    'ext_dropout':0.1,\n",
    "    'lr':0.002,\n",
    "    'accum_count':2,\n",
    "    'use_interval':True\n",
    "})\n",
    "\n",
    "\n",
    "args = Namespace(**ext_args_train_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(accum_count=2, alpha=0.95, batch_size=300, beam_size=5, bert_data_path='./data', beta1=0.9, beta2=0.999, block_trigram=True, dec_dropout=0.2, dec_ff_size=2048, dec_heads=8, dec_hidden_size=768, dec_layers=6, enc_dropout=0.2, enc_ff_size=512, enc_hidden_size=512, enc_layers=6, encoder='bert', ext_dropout=0.1, ext_ff_size=2048, ext_heads=8, ext_hidden_size=768, ext_layers=2, finetune_bert=True, generator_shard_size=32, gpu_ranks=[0], label_smoothing=0.1, large=False, load_from_extractive='', log_file='./logs/train_ext', lr=0.002, lr_bert=0.002, lr_dec=0.002, max_grad_norm=0, max_length=200, max_pos=512, max_tgt_len=140, min_length=50, mode='train', model_path='./model_files/trained/ext', optim='adam', param_init=0, param_init_glorot=True, recall_eval=False, report_every=1, report_rouge=True, result_path='../results/trained/ext', save_checkpoint_steps=15, seed=666, sep_optim=False, share_emb=False, task='ext', temp_dir='./temp', test_all=False, test_batch_size=200, test_from='./model_files/pre_trained/abs_transformer/cnndm_baseline_best.pt', test_start_from=-1, train_from='./model_files/pre_trained/ext/bertext_cnndm_transformer.pt', train_steps=18031, use_bert_emb=False, use_interval=True, user_interval=True, visible_gpus='-1', warmup_steps=1, warmup_steps_bert=8000, warmup_steps_dec=8000, world_size=1)\n"
     ]
    }
   ],
   "source": [
    "print(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-05-09 19:21:37,445 INFO] Device ID -1\n",
      "[2020-05-09 19:21:37,446 INFO] Device cpu\n",
      "[2020-05-09 19:21:37,451 INFO] Loading checkpoint from ./model_files/pre_trained/ext/bertext_cnndm_transformer.pt\n",
      "[2020-05-09 19:21:37,976 INFO] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at ./temp/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
      "[2020-05-09 19:21:37,978 INFO] Model config {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "[2020-05-09 19:21:38,056 INFO] loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at ./temp/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['model', 'opt', 'optim'])\n",
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-05-09 19:21:40,728 INFO] * number of parameters: 120512513\n",
      "[2020-05-09 19:21:40,728 INFO] Start training...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpu_rank 0\n",
      "pts ['./data/train.pt']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-05-09 19:21:42,474 INFO] Loading train dataset from ./data/train.pt, number of examples: 2955\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step=18001, trains_steps=18031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-05-09 19:21:47,806 INFO] Step 18001/18031; xent: 1.79; lr: 0.0000149;   1 docs/s;      5 sec\n",
      "[2020-05-09 19:21:52,916 INFO] Step 18002/18031; xent: 1.00; lr: 0.0000149;   1 docs/s;     10 sec\n",
      "[2020-05-09 19:21:57,968 INFO] Step 18003/18031; xent: 2.12; lr: 0.0000149;   1 docs/s;     15 sec\n",
      "[2020-05-09 19:22:03,144 INFO] Step 18004/18031; xent: 1.07; lr: 0.0000149;   1 docs/s;     21 sec\n",
      "[2020-05-09 19:22:08,255 INFO] Step 18005/18031; xent: 1.03; lr: 0.0000149;   1 docs/s;     26 sec\n",
      "[2020-05-09 19:22:13,359 INFO] Step 18006/18031; xent: 0.40; lr: 0.0000149;   1 docs/s;     31 sec\n",
      "[2020-05-09 19:22:18,460 INFO] Step 18007/18031; xent: 0.30; lr: 0.0000149;   1 docs/s;     36 sec\n",
      "[2020-05-09 19:22:23,953 INFO] Step 18008/18031; xent: 0.91; lr: 0.0000149;   1 docs/s;     41 sec\n",
      "[2020-05-09 19:22:29,269 INFO] Step 18009/18031; xent: 0.24; lr: 0.0000149;   1 docs/s;     47 sec\n",
      "[2020-05-09 19:22:34,098 INFO] Step 18010/18031; xent: 0.17; lr: 0.0000149;   1 docs/s;     52 sec\n",
      "[2020-05-09 19:22:39,210 INFO] Step 18011/18031; xent: 1.02; lr: 0.0000149;   1 docs/s;     57 sec\n",
      "[2020-05-09 19:22:44,246 INFO] Step 18012/18031; xent: 0.09; lr: 0.0000149;   1 docs/s;     62 sec\n",
      "[2020-05-09 19:22:49,329 INFO] Step 18013/18031; xent: 2.43; lr: 0.0000149;   1 docs/s;     67 sec\n",
      "[2020-05-09 19:22:54,277 INFO] Step 18014/18031; xent: 0.94; lr: 0.0000149;   1 docs/s;     72 sec\n",
      "[2020-05-09 19:22:59,156 INFO] Step 18015/18031; xent: 0.76; lr: 0.0000149;   1 docs/s;     77 sec\n",
      "[2020-05-09 19:22:59,160 INFO] Saving checkpoint ./model_files/trained/ext/model_step_18015.pt\n",
      "[2020-05-09 19:23:04,902 INFO] Step 18016/18031; xent: 2.88; lr: 0.0000149;   1 docs/s;     82 sec\n",
      "[2020-05-09 19:23:10,121 INFO] Step 18017/18031; xent: 0.07; lr: 0.0000149;   1 docs/s;     88 sec\n",
      "[2020-05-09 19:23:15,346 INFO] Step 18018/18031; xent: 2.45; lr: 0.0000149;   1 docs/s;     93 sec\n",
      "[2020-05-09 19:23:20,802 INFO] Step 18019/18031; xent: 2.14; lr: 0.0000149;   1 docs/s;     98 sec\n",
      "[2020-05-09 19:23:25,889 INFO] Step 18020/18031; xent: 0.12; lr: 0.0000149;   1 docs/s;    103 sec\n",
      "[2020-05-09 19:23:31,518 INFO] Step 18021/18031; xent: 1.93; lr: 0.0000149;   1 docs/s;    109 sec\n",
      "[2020-05-09 19:23:36,997 INFO] Step 18022/18031; xent: 2.59; lr: 0.0000149;   1 docs/s;    115 sec\n",
      "[2020-05-09 19:23:42,103 INFO] Step 18023/18031; xent: 1.66; lr: 0.0000149;   1 docs/s;    120 sec\n",
      "[2020-05-09 19:23:47,363 INFO] Step 18024/18031; xent: 0.51; lr: 0.0000149;   1 docs/s;    125 sec\n",
      "[2020-05-09 19:23:52,528 INFO] Step 18025/18031; xent: 1.16; lr: 0.0000149;   1 docs/s;    130 sec\n",
      "[2020-05-09 19:23:57,595 INFO] Step 18026/18031; xent: 0.54; lr: 0.0000149;   1 docs/s;    135 sec\n",
      "[2020-05-09 19:24:02,869 INFO] Step 18027/18031; xent: 1.42; lr: 0.0000149;   1 docs/s;    140 sec\n",
      "[2020-05-09 19:24:08,154 INFO] Step 18028/18031; xent: 2.09; lr: 0.0000149;   1 docs/s;    146 sec\n",
      "[2020-05-09 19:24:13,304 INFO] Step 18029/18031; xent: 0.80; lr: 0.0000149;   1 docs/s;    151 sec\n",
      "[2020-05-09 19:24:18,674 INFO] Step 18030/18031; xent: 1.84; lr: 0.0000149;   1 docs/s;    156 sec\n",
      "[2020-05-09 19:24:18,678 INFO] Saving checkpoint ./model_files/trained/ext/model_step_18030.pt\n",
      "[2020-05-09 19:24:24,670 INFO] Step 18031/18031; xent: 0.48; lr: 0.0000149;   1 docs/s;    162 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pts ['./data/train.pt']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-05-09 19:24:25,923 INFO] Loading train dataset from ./data/train.pt, number of examples: 2955\n"
     ]
    }
   ],
   "source": [
    "# training the model for extractive summarization\n",
    "train_single_ext(args, device_id=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate the trained model\n",
    "\n",
    "Using the trained model we are generating and evaluating the extractive summarization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-05-09 19:24:26,168 INFO] Loading checkpoint from ./model_files/trained/ext/model_step_18030.pt\n",
      "[2020-05-09 19:24:26,485 INFO] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at ./temp/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
      "[2020-05-09 19:24:26,486 INFO] Model config {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "[2020-05-09 19:24:26,561 INFO] loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at ./temp/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(accum_count=2, alpha=0.95, batch_size=300, beam_size=5, bert_data_path='./data', beta1=0.9, beta2=0.999, block_trigram=True, dec_dropout=0.2, dec_ff_size=2048, dec_heads=8, dec_hidden_size=768, dec_layers=6, enc_dropout=0.2, enc_ff_size=512, enc_hidden_size=512, enc_layers=6, encoder='bert', ext_dropout=0.1, ext_ff_size=2048, ext_heads=8, ext_hidden_size=768, ext_layers=2, finetune_bert=True, generator_shard_size=32, gpu_ranks=[0], label_smoothing=0.1, large=False, load_from_extractive='', log_file='./logs/ext_trained', lr=0.002, lr_bert=0.002, lr_dec=0.002, max_grad_norm=0, max_length=200, max_pos=512, max_tgt_len=140, min_length=50, mode='test', model_path='./model_files/trained/ext', optim='adam', param_init=0, param_init_glorot=True, recall_eval=False, report_every=1, report_rouge=True, result_path='./results/trained/ext_trained', save_checkpoint_steps=15, seed=666, sep_optim=False, share_emb=False, task='ext', temp_dir='./temp', test_all=False, test_batch_size=200, test_from='./model_files/trained/ext/model_step_18030.pt', test_start_from=-1, train_from='./model_files/pre_trained/ext/bertext_cnndm_transformer.pt', train_steps=18031, use_bert_emb=False, use_interval=True, user_interval=True, visible_gpus='-1', warmup_steps=1, warmup_steps_bert=8000, warmup_steps_dec=8000, world_size=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-05-09 19:24:28,865 INFO] Loading test dataset from ./data/test.pt, number of examples: 369\n",
      "[2020-05-09 19:24:28,872 INFO] * number of parameters: 120512513\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pts ['./data/test.pt']\n",
      "gpu_rank 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-05-09 19:27:07,182 [MainThread  ] [INFO ]  Writing summaries.\n",
      "[2020-05-09 19:27:07,182 INFO] Writing summaries.\n",
      "2020-05-09 19:27:07,184 [MainThread  ] [INFO ]  Processing summaries. Saving system files to ./temp/tmp1osroyne/system and model files to ./temp/tmp1osroyne/model.\n",
      "[2020-05-09 19:27:07,184 INFO] Processing summaries. Saving system files to ./temp/tmp1osroyne/system and model files to ./temp/tmp1osroyne/model.\n",
      "2020-05-09 19:27:07,185 [MainThread  ] [INFO ]  Processing files in ./temp/rouge-tmp-2020-05-09-19-27-07/candidate/.\n",
      "[2020-05-09 19:27:07,185 INFO] Processing files in ./temp/rouge-tmp-2020-05-09-19-27-07/candidate/.\n",
      "2020-05-09 19:27:07,229 [MainThread  ] [INFO ]  Saved processed files to ./temp/tmp1osroyne/system.\n",
      "[2020-05-09 19:27:07,229 INFO] Saved processed files to ./temp/tmp1osroyne/system.\n",
      "2020-05-09 19:27:07,230 [MainThread  ] [INFO ]  Processing files in ./temp/rouge-tmp-2020-05-09-19-27-07/reference/.\n",
      "[2020-05-09 19:27:07,230 INFO] Processing files in ./temp/rouge-tmp-2020-05-09-19-27-07/reference/.\n",
      "2020-05-09 19:27:07,280 [MainThread  ] [INFO ]  Saved processed files to ./temp/tmp1osroyne/model.\n",
      "[2020-05-09 19:27:07,280 INFO] Saved processed files to ./temp/tmp1osroyne/model.\n",
      "2020-05-09 19:27:07,286 [MainThread  ] [INFO ]  Written ROUGE configuration to ./temp/tmpx7cq0pg9/rouge_conf.xml\n",
      "[2020-05-09 19:27:07,286 INFO] Written ROUGE configuration to ./temp/tmpx7cq0pg9/rouge_conf.xml\n",
      "2020-05-09 19:27:07,287 [MainThread  ] [INFO ]  Running ROUGE with command perl ./ROUGE-1.5.5/ROUGE-1.5.5.pl -e ./ROUGE-1.5.5/data -c 95 -m -r 1000 -n 2 -a ./temp/tmpx7cq0pg9/rouge_conf.xml\n",
      "[2020-05-09 19:27:07,287 INFO] Running ROUGE with command perl ./ROUGE-1.5.5/ROUGE-1.5.5.pl -e ./ROUGE-1.5.5/data -c 95 -m -r 1000 -n 2 -a ./temp/tmpx7cq0pg9/rouge_conf.xml\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "369\n",
      "369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-05-09 19:27:21,876 INFO] Rouges at step 0 \n",
      ">> ROUGE-F(1/2/3/l): 30.20/12.20/26.04\n",
      "ROUGE-R(1/2/3/l): 25.13/10.28/21.49\n",
      "\n",
      "[2020-05-09 19:27:21,877 INFO] Validation xent: 2.43483 at step 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------\n",
      "1 ROUGE-1 Average_R: 0.25128 (95%-conf.int. 0.23658 - 0.26767)\n",
      "1 ROUGE-1 Average_P: 0.50811 (95%-conf.int. 0.49359 - 0.52156)\n",
      "1 ROUGE-1 Average_F: 0.30204 (95%-conf.int. 0.29001 - 0.31453)\n",
      "---------------------------------------------\n",
      "1 ROUGE-2 Average_R: 0.10276 (95%-conf.int. 0.09280 - 0.11371)\n",
      "1 ROUGE-2 Average_P: 0.20040 (95%-conf.int. 0.18753 - 0.21366)\n",
      "1 ROUGE-2 Average_F: 0.12198 (95%-conf.int. 0.11282 - 0.13200)\n",
      "---------------------------------------------\n",
      "1 ROUGE-L Average_R: 0.21493 (95%-conf.int. 0.20285 - 0.22879)\n",
      "1 ROUGE-L Average_P: 0.44402 (95%-conf.int. 0.42986 - 0.45792)\n",
      "1 ROUGE-L Average_F: 0.26038 (95%-conf.int. 0.25049 - 0.27132)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ext_args_dict = arg_params\n",
    "ext_args_dict.update({\n",
    "            'bert_data_path':'./data',\n",
    "    'log_file':'./logs/ext_trained',\n",
    "    'model_path':'./model_files/trained/ext',\n",
    "    'result_path':'./results/trained/ext_trained',\n",
    "    'test_from':f'./model_files/trained/ext/model_step_{str(18001+training_steps-1)}.pt',\n",
    "    'task':'ext',\n",
    "    'mode':'test',\n",
    "\n",
    "    'batch_size':300,\n",
    "    'ext_dropout':0.1,\n",
    "    'accum_count':2\n",
    "})\n",
    "\n",
    "args = Namespace(**ext_args_dict)\n",
    "\n",
    "# Generating and scoring the extractive summaries using the trained model\n",
    "test_ext(args, device_id=-1, pt=args.test_from, step=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Abstractive Summarization (Transformer Basline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_steps = 30\n",
    "abs_args_train_dict = arg_params\n",
    "\n",
    "abs_args_train_dict.update({\n",
    "    \n",
    "            'bert_data_path':'./data',\n",
    "    'log_file':'./logs/train_abs_transformer',\n",
    "    'mode':'train',\n",
    "    'model_path':'./model_files/trained/abs_transformer',\n",
    "    'result_path':'./results/trained/abs_transformer',\n",
    "    'train_from':'./model_files/pre_trained/abs_transformer/cnndm_baseline_best.pt',\n",
    "    'task': abs,\n",
    "\n",
    "    \n",
    "    'accum_count':5,\n",
    "    'batch_size':300,\n",
    "    'dec_dropout':0.1,\n",
    "    'lr':0.05,\n",
    "    'save_checkpoint_steps':15,\n",
    "    'sep_optim':False,\n",
    "    'train_steps':38001 + training_steps,\n",
    "    'use_bert_emb':True,\n",
    "    'warmup_steps':1,\n",
    "    'report_every':50,\n",
    "    'enc_hidden_size':512 ,\n",
    "'enc_layers':6,\n",
    "'enc_ff_size': 2048,\n",
    "'enc_dropout': 0.1,\n",
    "'dec_layers': 6,\n",
    "'dec_hidden_size': 512,\n",
    "'dec_ff_size':2048,\n",
    "'encoder': 'baseline'\n",
    "\n",
    "})\n",
    "\n",
    "\n",
    "args = Namespace(**abs_args_train_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-05-09 19:27:21,908 INFO] Namespace(accum_count=5, alpha=0.95, batch_size=300, beam_size=5, bert_data_path='./data', beta1=0.9, beta2=0.999, block_trigram=True, dec_dropout=0.1, dec_ff_size=2048, dec_heads=8, dec_hidden_size=512, dec_layers=6, enc_dropout=0.1, enc_ff_size=2048, enc_hidden_size=512, enc_layers=6, encoder='baseline', ext_dropout=0.1, ext_ff_size=2048, ext_heads=8, ext_hidden_size=768, ext_layers=2, finetune_bert=True, generator_shard_size=32, gpu_ranks=[0], label_smoothing=0.1, large=False, load_from_extractive='', log_file='./logs/train_abs_transformer', lr=0.05, lr_bert=0.002, lr_dec=0.002, max_grad_norm=0, max_length=200, max_pos=512, max_tgt_len=140, min_length=50, mode='train', model_path='./model_files/trained/abs_transformer', optim='adam', param_init=0, param_init_glorot=True, recall_eval=False, report_every=50, report_rouge=True, result_path='./results/trained/abs_transformer', save_checkpoint_steps=15, seed=666, sep_optim=False, share_emb=False, task=<built-in function abs>, temp_dir='./temp', test_all=False, test_batch_size=200, test_from='./model_files/trained/ext/model_step_18030.pt', test_start_from=-1, train_from='./model_files/pre_trained/abs_transformer/cnndm_baseline_best.pt', train_steps=38031, use_bert_emb=True, use_interval=True, user_interval=True, visible_gpus='-1', warmup_steps=1, warmup_steps_bert=8000, warmup_steps_dec=8000, world_size=1)\n",
      "[2020-05-09 19:27:21,909 INFO] Device ID -1\n",
      "[2020-05-09 19:27:21,910 INFO] Device cpu\n",
      "[2020-05-09 19:27:21,912 INFO] Loading checkpoint from ./model_files/pre_trained/abs_transformer/cnndm_baseline_best.pt\n",
      "[2020-05-09 19:27:22,317 INFO] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at ./temp/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
      "[2020-05-09 19:27:22,318 INFO] Model config {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "[2020-05-09 19:27:22,395 INFO] loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at ./temp/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['model', 'opt', 'optims'])\n",
      "False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-05-09 19:27:26,314 INFO] loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at ./temp/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "[2020-05-09 19:27:26,349 INFO] * number of parameters: 75951418\n",
      "[2020-05-09 19:27:26,350 INFO] Start training...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpu_rank 0\n",
      "pts ['./data/train.pt']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-05-09 19:27:27,544 INFO] Loading train dataset from ./data/train.pt, number of examples: 2955\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step=38001, Train_steps=38031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-05-09 19:28:37,923 INFO] Saving checkpoint ./model_files/trained/abs_transformer/model_step_38010.pt\n",
      "[2020-05-09 19:30:26,395 INFO] Saving checkpoint ./model_files/trained/abs_transformer/model_step_38025.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pts ['./data/train.pt']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-05-09 19:31:11,705 INFO] Loading train dataset from ./data/train.pt, number of examples: 2955\n"
     ]
    }
   ],
   "source": [
    "# training the model for generating abstractive summaries\n",
    "train_abs_single(args, device_id=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-05-09 19:31:11,923 INFO] Loading checkpoint from ./model_files/trained/abs_transformer/model_step_38025.pt\n",
      "[2020-05-09 19:31:12,200 INFO] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at ./temp/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
      "[2020-05-09 19:31:12,201 INFO] Model config {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "[2020-05-09 19:31:12,269 INFO] loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at ./temp/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(accum_count=5, alpha=0.95, batch_size=300, beam_size=5, bert_data_path='./data', beta1=0.9, beta2=0.999, block_trigram=True, dec_dropout=0.1, dec_ff_size=2048, dec_heads=8, dec_hidden_size=512, dec_layers=6, enc_dropout=0.1, enc_ff_size=2048, enc_hidden_size=512, enc_layers=6, encoder='baseline', ext_dropout=0.1, ext_ff_size=2048, ext_heads=8, ext_hidden_size=768, ext_layers=2, finetune_bert=True, generator_shard_size=32, gpu_ranks=[0], label_smoothing=0.1, large=False, load_from_extractive='', log_file='./logs/abs_transformers_trained', lr=0.05, lr_bert=0.002, lr_dec=0.002, max_grad_norm=0, max_length=200, max_pos=512, max_tgt_len=140, min_length=50, mode='test', model_path='./model_files/trained/abs_transformer/', optim='adam', param_init=0, param_init_glorot=True, recall_eval=False, report_every=50, report_rouge=True, result_path='./results/trained/abs_transformer', save_checkpoint_steps=15, seed=666, sep_optim=False, share_emb=False, task='abs', temp_dir='./temp', test_all=False, test_batch_size=200, test_from='./model_files/trained/abs_transformer/model_step_38025.pt', test_start_from=-1, train_from='./model_files/pre_trained/abs_transformer/cnndm_baseline_best.pt', train_steps=38031, use_bert_emb=True, use_interval=True, user_interval=True, visible_gpus='-1', warmup_steps=1, warmup_steps_bert=8000, warmup_steps_dec=8000, world_size=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-05-09 19:31:16,037 INFO] Loading test dataset from ./data/test.pt, number of examples: 369\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pts ['./data/test.pt']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-05-09 19:31:16,119 INFO] loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at ./temp/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "[2020-05-09 20:50:40,526 INFO] Calculating Rouge\n",
      "2020-05-09 20:50:40,572 [MainThread  ] [INFO ]  Writing summaries.\n",
      "[2020-05-09 20:50:40,572 INFO] Writing summaries.\n",
      "2020-05-09 20:50:40,574 [MainThread  ] [INFO ]  Processing summaries. Saving system files to ./temp/tmpn0wozr0p/system and model files to ./temp/tmpn0wozr0p/model.\n",
      "[2020-05-09 20:50:40,574 INFO] Processing summaries. Saving system files to ./temp/tmpn0wozr0p/system and model files to ./temp/tmpn0wozr0p/model.\n",
      "2020-05-09 20:50:40,577 [MainThread  ] [INFO ]  Processing files in ./temp/rouge-tmp-2020-05-09-20-50-40/candidate/.\n",
      "[2020-05-09 20:50:40,577 INFO] Processing files in ./temp/rouge-tmp-2020-05-09-20-50-40/candidate/.\n",
      "2020-05-09 20:50:40,625 [MainThread  ] [INFO ]  Saved processed files to ./temp/tmpn0wozr0p/system.\n",
      "[2020-05-09 20:50:40,625 INFO] Saved processed files to ./temp/tmpn0wozr0p/system.\n",
      "2020-05-09 20:50:40,627 [MainThread  ] [INFO ]  Processing files in ./temp/rouge-tmp-2020-05-09-20-50-40/reference/.\n",
      "[2020-05-09 20:50:40,627 INFO] Processing files in ./temp/rouge-tmp-2020-05-09-20-50-40/reference/.\n",
      "2020-05-09 20:50:40,678 [MainThread  ] [INFO ]  Saved processed files to ./temp/tmpn0wozr0p/model.\n",
      "[2020-05-09 20:50:40,678 INFO] Saved processed files to ./temp/tmpn0wozr0p/model.\n",
      "2020-05-09 20:50:40,684 [MainThread  ] [INFO ]  Written ROUGE configuration to ./temp/tmpish6tac7/rouge_conf.xml\n",
      "[2020-05-09 20:50:40,684 INFO] Written ROUGE configuration to ./temp/tmpish6tac7/rouge_conf.xml\n",
      "2020-05-09 20:50:40,685 [MainThread  ] [INFO ]  Running ROUGE with command perl ./ROUGE-1.5.5/ROUGE-1.5.5.pl -e ./ROUGE-1.5.5/data -c 95 -m -r 1000 -n 2 -a ./temp/tmpish6tac7/rouge_conf.xml\n",
      "[2020-05-09 20:50:40,685 INFO] Running ROUGE with command perl ./ROUGE-1.5.5/ROUGE-1.5.5.pl -e ./ROUGE-1.5.5/data -c 95 -m -r 1000 -n 2 -a ./temp/tmpish6tac7/rouge_conf.xml\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "369\n",
      "369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-05-09 20:50:53,340 INFO] Rouges at step 0 \n",
      ">> ROUGE-F(1/2/3/l): 27.62/11.06/23.48\n",
      "ROUGE-R(1/2/3/l): 21.51/8.69/18.08\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------\n",
      "1 ROUGE-1 Average_R: 0.21512 (95%-conf.int. 0.20138 - 0.22990)\n",
      "1 ROUGE-1 Average_P: 0.54829 (95%-conf.int. 0.53100 - 0.56577)\n",
      "1 ROUGE-1 Average_F: 0.27616 (95%-conf.int. 0.26313 - 0.28898)\n",
      "---------------------------------------------\n",
      "1 ROUGE-2 Average_R: 0.08687 (95%-conf.int. 0.07851 - 0.09528)\n",
      "1 ROUGE-2 Average_P: 0.21848 (95%-conf.int. 0.20456 - 0.23297)\n",
      "1 ROUGE-2 Average_F: 0.11064 (95%-conf.int. 0.10257 - 0.11962)\n",
      "---------------------------------------------\n",
      "1 ROUGE-L Average_R: 0.18084 (95%-conf.int. 0.17001 - 0.19243)\n",
      "1 ROUGE-L Average_P: 0.47653 (95%-conf.int. 0.45968 - 0.49282)\n",
      "1 ROUGE-L Average_F: 0.23477 (95%-conf.int. 0.22417 - 0.24531)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "abs_args_dict = arg_params\n",
    "\n",
    "abs_args_dict.update({\n",
    "            'bert_data_path':'./data',\n",
    "    'log_file':'./logs/abs_transformers_trained',\n",
    "    'model_path':'./model_files/trained/abs_transformer/',\n",
    "    'result_path':'./results/trained/abs_transformer',\n",
    "    'test_from':f'./model_files/trained/abs_transformer/model_step_38025.pt',\n",
    "    'task':'abs',\n",
    "    'mode':'test',\n",
    "    \n",
    "    'batch_size':300,\n",
    "    'test_batch_size':200,\n",
    "    'max_pos':512,\n",
    "    'max_length':200,\n",
    "    'min_length':50,\n",
    "        \n",
    "    'sep_optim':False,\n",
    "\n",
    "})\n",
    "\n",
    "args = Namespace(**abs_args_dict)\n",
    "\n",
    "# Generating and scoring the abstractive summaries using the trained model\n",
    "test_abs(args, device_id=-1, pt=args.test_from, step=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Abstractive Summarization (BertExt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_steps = 30\n",
    "abs_args_train_dict = arg_params\n",
    "\n",
    "abs_args_train_dict.update({\n",
    "    \n",
    "            'bert_data_path':'./data',\n",
    "    'log_file':'./logs/train_abs',\n",
    "    'mode':'train',\n",
    "    'model_path':'./model_files/trained/abs',\n",
    "    'result_path':'./results/trained/abs',\n",
    "    'train_from':'./model_files/pre_trained/abs_bertextabs/model_step_148000.pt',\n",
    "        'load_from_extractive':f'./model_files/trained/ext/model_step_{str(18001 + training_steps -1)}.pt',\n",
    "    'task': abs,\n",
    "    'save_checkpoint_steps':15,\n",
    "    'batch_size':300,\n",
    "    'train_steps':148001+training_steps,\n",
    "    'report_every':1,\n",
    "    'accum_count':5,\n",
    "    'warmup_steps_bert':1,\n",
    "    'warmup_steps_dec':1,\n",
    "  \n",
    "'dec_dropout':0.2,\n",
    "'sep_optim':True,\n",
    "'lr_bert':0.002,\n",
    "'lr_dec':0.2,\n",
    "'use_bert_emb':True,\n",
    "'use_interval':True,\n",
    "'max_pos':512\n",
    "})\n",
    "\n",
    "\n",
    "args = Namespace(**abs_args_train_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-05-09 20:50:53,369 INFO] Namespace(accum_count=5, alpha=0.95, batch_size=300, beam_size=5, bert_data_path='./data', beta1=0.9, beta2=0.999, block_trigram=True, dec_dropout=0.2, dec_ff_size=2048, dec_heads=8, dec_hidden_size=512, dec_layers=6, enc_dropout=0.1, enc_ff_size=2048, enc_hidden_size=512, enc_layers=6, encoder='baseline', ext_dropout=0.1, ext_ff_size=2048, ext_heads=8, ext_hidden_size=768, ext_layers=2, finetune_bert=True, generator_shard_size=32, gpu_ranks=[0], label_smoothing=0.1, large=False, load_from_extractive='./model_files/trained/ext/model_step_18030.pt', log_file='./logs/train_abs', lr=0.05, lr_bert=0.002, lr_dec=0.2, max_grad_norm=0, max_length=200, max_pos=512, max_tgt_len=140, min_length=50, mode='train', model_path='./model_files/trained/abs', optim='adam', param_init=0, param_init_glorot=True, recall_eval=False, report_every=1, report_rouge=True, result_path='./results/trained/abs', save_checkpoint_steps=15, seed=666, sep_optim=True, share_emb=False, task=<built-in function abs>, temp_dir='./temp', test_all=False, test_batch_size=200, test_from='./model_files/trained/abs_transformer/model_step_38025.pt', test_start_from=-1, train_from='./model_files/pre_trained/abs_bertextabs/model_step_148000.pt', train_steps=148031, use_bert_emb=True, use_interval=True, user_interval=True, visible_gpus='-1', warmup_steps=1, warmup_steps_bert=1, warmup_steps_dec=1, world_size=1)\n",
      "[2020-05-09 20:50:53,370 INFO] Device ID -1\n",
      "[2020-05-09 20:50:53,371 INFO] Device cpu\n",
      "[2020-05-09 20:50:53,373 INFO] Loading checkpoint from ./model_files/pre_trained/abs_bertextabs/model_step_148000.pt\n",
      "[2020-05-09 20:50:54,141 INFO] Loading bert from extractive model ./model_files/trained/ext/model_step_18030.pt\n",
      "[2020-05-09 20:50:54,863 INFO] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at ./temp/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
      "[2020-05-09 20:50:54,864 INFO] Model config {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "[2020-05-09 20:50:54,939 INFO] loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at ./temp/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
      "[2020-05-09 20:50:59,272 INFO] loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at ./temp/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "[2020-05-09 20:50:59,310 INFO] * number of parameters: 180222522\n",
      "[2020-05-09 20:50:59,310 INFO] Start training...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpu_rank 0\n",
      "pts ['./data/train.pt']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-05-09 20:51:00,531 INFO] Loading train dataset from ./data/train.pt, number of examples: 2955\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step=148001, Train_steps=148031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-05-09 20:51:17,324 INFO] Step 148001/148031; acc:  26.90; ppl: 87.66; xent: 4.47; lr: 0.00000520;   0/ 37 tok/s;     17 sec\n",
      "[2020-05-09 20:51:32,878 INFO] Step 148002/148031; acc:  34.17; ppl: 61.84; xent: 4.12; lr: 0.00000520;   0/ 34 tok/s;     32 sec\n",
      "[2020-05-09 20:51:49,484 INFO] Step 148003/148031; acc:  23.77; ppl: 105.11; xent: 4.65; lr: 0.00000520;   0/ 40 tok/s;     49 sec\n",
      "[2020-05-09 20:52:06,043 INFO] Step 148004/148031; acc:  17.99; ppl: 188.99; xent: 5.24; lr: 0.00000520;   0/ 42 tok/s;     66 sec\n",
      "[2020-05-09 20:52:22,765 INFO] Step 148005/148031; acc:  29.32; ppl: 83.67; xent: 4.43; lr: 0.00000520;   0/ 36 tok/s;     82 sec\n",
      "[2020-05-09 20:52:22,771 INFO] Saving checkpoint ./model_files/trained/abs/model_step_148005.pt\n",
      "[2020-05-09 20:52:39,505 INFO] Step 148006/148031; acc:  31.46; ppl: 65.89; xent: 4.19; lr: 0.00000520;   0/ 34 tok/s;     99 sec\n",
      "[2020-05-09 20:52:55,507 INFO] Step 148007/148031; acc:  29.44; ppl: 69.42; xent: 4.24; lr: 0.00000520;   0/ 38 tok/s;    115 sec\n",
      "[2020-05-09 20:53:12,059 INFO] Step 148008/148031; acc:  26.19; ppl: 86.04; xent: 4.45; lr: 0.00000520;   0/ 42 tok/s;    132 sec\n",
      "[2020-05-09 20:53:27,800 INFO] Step 148009/148031; acc:  43.58; ppl: 25.85; xent: 3.25; lr: 0.00000520;   0/ 33 tok/s;    147 sec\n",
      "[2020-05-09 20:53:44,044 INFO] Step 148010/148031; acc:  27.73; ppl: 63.38; xent: 4.15; lr: 0.00000520;   0/ 40 tok/s;    164 sec\n",
      "[2020-05-09 20:54:00,371 INFO] Step 148011/148031; acc:  32.26; ppl: 52.07; xent: 3.95; lr: 0.00000520;   0/ 36 tok/s;    180 sec\n",
      "[2020-05-09 20:54:16,815 INFO] Step 148012/148031; acc:  27.86; ppl: 78.38; xent: 4.36; lr: 0.00000520;   0/ 41 tok/s;    196 sec\n",
      "[2020-05-09 20:54:32,934 INFO] Step 148013/148031; acc:  30.73; ppl: 54.83; xent: 4.00; lr: 0.00000520;   0/ 37 tok/s;    212 sec\n",
      "[2020-05-09 20:54:49,333 INFO] Step 148014/148031; acc:  24.64; ppl: 89.39; xent: 4.49; lr: 0.00000520;   0/ 42 tok/s;    229 sec\n",
      "[2020-05-09 20:55:05,970 INFO] Step 148015/148031; acc:  37.99; ppl: 35.37; xent: 3.57; lr: 0.00000520;   0/ 42 tok/s;    245 sec\n",
      "[2020-05-09 20:55:22,661 INFO] Step 148016/148031; acc:  30.17; ppl: 57.88; xent: 4.06; lr: 0.00000520;   0/ 35 tok/s;    262 sec\n",
      "[2020-05-09 20:55:38,907 INFO] Step 148017/148031; acc:  31.08; ppl: 65.68; xent: 4.18; lr: 0.00000520;   0/ 43 tok/s;    278 sec\n",
      "[2020-05-09 20:55:55,101 INFO] Step 148018/148031; acc:  36.95; ppl: 42.84; xent: 3.76; lr: 0.00000520;   0/ 40 tok/s;    295 sec\n",
      "[2020-05-09 20:56:11,758 INFO] Step 148019/148031; acc:  32.09; ppl: 57.66; xent: 4.05; lr: 0.00000520;   0/ 42 tok/s;    311 sec\n",
      "[2020-05-09 20:56:28,026 INFO] Step 148020/148031; acc:  29.21; ppl: 57.24; xent: 4.05; lr: 0.00000520;   0/ 43 tok/s;    327 sec\n",
      "[2020-05-09 20:56:28,032 INFO] Saving checkpoint ./model_files/trained/abs/model_step_148020.pt\n",
      "[2020-05-09 20:56:45,144 INFO] Step 148021/148031; acc:  29.14; ppl: 70.98; xent: 4.26; lr: 0.00000520;   0/ 37 tok/s;    345 sec\n",
      "[2020-05-09 20:57:01,821 INFO] Step 148022/148031; acc:  34.16; ppl: 50.45; xent: 3.92; lr: 0.00000520;   0/ 41 tok/s;    361 sec\n",
      "[2020-05-09 20:57:17,904 INFO] Step 148023/148031; acc:  34.24; ppl: 46.76; xent: 3.85; lr: 0.00000520;   0/ 43 tok/s;    377 sec\n",
      "[2020-05-09 20:57:34,473 INFO] Step 148024/148031; acc:  28.23; ppl: 51.65; xent: 3.94; lr: 0.00000520;   0/ 38 tok/s;    394 sec\n",
      "[2020-05-09 20:57:51,531 INFO] Step 148025/148031; acc:  35.97; ppl: 42.07; xent: 3.74; lr: 0.00000520;   0/ 41 tok/s;    411 sec\n",
      "[2020-05-09 20:58:07,987 INFO] Step 148026/148031; acc:  29.21; ppl: 62.05; xent: 4.13; lr: 0.00000520;   0/ 42 tok/s;    427 sec\n",
      "[2020-05-09 20:58:24,176 INFO] Step 148027/148031; acc:  33.39; ppl: 45.66; xent: 3.82; lr: 0.00000520;   0/ 36 tok/s;    444 sec\n",
      "[2020-05-09 20:58:40,212 INFO] Step 148028/148031; acc:  40.47; ppl: 32.91; xent: 3.49; lr: 0.00000520;   0/ 37 tok/s;    460 sec\n",
      "[2020-05-09 20:58:56,696 INFO] Step 148029/148031; acc:  27.98; ppl: 64.00; xent: 4.16; lr: 0.00000520;   0/ 40 tok/s;    476 sec\n",
      "[2020-05-09 20:59:13,612 INFO] Step 148030/148031; acc:  30.65; ppl: 54.79; xent: 4.00; lr: 0.00000520;   0/ 41 tok/s;    493 sec\n",
      "[2020-05-09 20:59:30,182 INFO] Step 148031/148031; acc:  34.18; ppl: 42.14; xent: 3.74; lr: 0.00000520;   0/ 40 tok/s;    510 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pts ['./data/train.pt']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-05-09 20:59:31,727 INFO] Loading train dataset from ./data/train.pt, number of examples: 2955\n"
     ]
    }
   ],
   "source": [
    "# Training the Bert model for generating abstractive summaries\n",
    "train_abs_single(args, device_id=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-05-09 21:03:06,251 INFO] Loading checkpoint from ./model_files/trained/abs/model_step_148020.pt\n",
      "[2020-05-09 21:03:06,758 INFO] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at ./temp/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
      "[2020-05-09 21:03:06,760 INFO] Model config {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "[2020-05-09 21:03:06,835 INFO] loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at ./temp/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(accum_count=5, alpha=0.95, batch_size=300, beam_size=5, bert_data_path='./data', beta1=0.9, beta2=0.999, block_trigram=True, dec_dropout=0.2, dec_ff_size=2048, dec_heads=8, dec_hidden_size=768, dec_layers=6, enc_dropout=0.1, enc_ff_size=512, enc_hidden_size=512, enc_layers=6, encoder='bert', ext_dropout=0.1, ext_ff_size=2048, ext_heads=8, ext_hidden_size=768, ext_layers=2, finetune_bert=True, generator_shard_size=32, gpu_ranks=[0], label_smoothing=0.1, large=False, load_from_extractive='./model_files/trained/ext/model_step_18030.pt', log_file='./logs/abs_bertextabs_trained', lr=0.05, lr_bert=0.002, lr_dec=0.2, max_grad_norm=0, max_length=200, max_pos=512, max_tgt_len=140, min_length=50, mode='test', model_path='./model_files/trained/abs_bertextabs/', optim='adam', param_init=0, param_init_glorot=True, recall_eval=False, report_every=1, report_rouge=True, result_path='./results/trained/abs_bertextabs', save_checkpoint_steps=15, seed=666, sep_optim=True, share_emb=False, task='abs', temp_dir='./temp', test_all=False, test_batch_size=200, test_from='./model_files/trained/abs/model_step_148020.pt', test_start_from=-1, train_from='./model_files/pre_trained/abs_bertextabs/model_step_148000.pt', train_steps=148031, use_bert_emb=True, use_interval=True, user_interval=True, visible_gpus='-1', warmup_steps=1, warmup_steps_bert=1, warmup_steps_dec=1, world_size=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-05-09 21:03:10,379 INFO] Loading test dataset from ./data/test.pt, number of examples: 369\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pts ['./data/test.pt']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-05-09 21:03:10,457 INFO] loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at ./temp/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "[2020-05-09 22:23:27,746 INFO] Calculating Rouge\n",
      "2020-05-09 22:23:27,793 [MainThread  ] [INFO ]  Writing summaries.\n",
      "[2020-05-09 22:23:27,793 INFO] Writing summaries.\n",
      "2020-05-09 22:23:27,795 [MainThread  ] [INFO ]  Processing summaries. Saving system files to ./temp/tmph8zoxwkw/system and model files to ./temp/tmph8zoxwkw/model.\n",
      "[2020-05-09 22:23:27,795 INFO] Processing summaries. Saving system files to ./temp/tmph8zoxwkw/system and model files to ./temp/tmph8zoxwkw/model.\n",
      "2020-05-09 22:23:27,797 [MainThread  ] [INFO ]  Processing files in ./temp/rouge-tmp-2020-05-09-22-23-27/candidate/.\n",
      "[2020-05-09 22:23:27,797 INFO] Processing files in ./temp/rouge-tmp-2020-05-09-22-23-27/candidate/.\n",
      "2020-05-09 22:23:27,845 [MainThread  ] [INFO ]  Saved processed files to ./temp/tmph8zoxwkw/system.\n",
      "[2020-05-09 22:23:27,845 INFO] Saved processed files to ./temp/tmph8zoxwkw/system.\n",
      "2020-05-09 22:23:27,846 [MainThread  ] [INFO ]  Processing files in ./temp/rouge-tmp-2020-05-09-22-23-27/reference/.\n",
      "[2020-05-09 22:23:27,846 INFO] Processing files in ./temp/rouge-tmp-2020-05-09-22-23-27/reference/.\n",
      "2020-05-09 22:23:27,902 [MainThread  ] [INFO ]  Saved processed files to ./temp/tmph8zoxwkw/model.\n",
      "[2020-05-09 22:23:27,902 INFO] Saved processed files to ./temp/tmph8zoxwkw/model.\n",
      "2020-05-09 22:23:27,908 [MainThread  ] [INFO ]  Written ROUGE configuration to ./temp/tmplk3d3mhj/rouge_conf.xml\n",
      "[2020-05-09 22:23:27,908 INFO] Written ROUGE configuration to ./temp/tmplk3d3mhj/rouge_conf.xml\n",
      "2020-05-09 22:23:27,909 [MainThread  ] [INFO ]  Running ROUGE with command perl ./ROUGE-1.5.5/ROUGE-1.5.5.pl -e ./ROUGE-1.5.5/data -c 95 -m -r 1000 -n 2 -a ./temp/tmplk3d3mhj/rouge_conf.xml\n",
      "[2020-05-09 22:23:27,909 INFO] Running ROUGE with command perl ./ROUGE-1.5.5/ROUGE-1.5.5.pl -e ./ROUGE-1.5.5/data -c 95 -m -r 1000 -n 2 -a ./temp/tmplk3d3mhj/rouge_conf.xml\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "369\n",
      "369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2020-05-09 22:23:42,309 INFO] Rouges at step 0 \n",
      ">> ROUGE-F(1/2/3/l): 29.28/10.66/24.97\n",
      "ROUGE-R(1/2/3/l): 24.29/8.91/20.57\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------\n",
      "1 ROUGE-1 Average_R: 0.24294 (95%-conf.int. 0.22840 - 0.25752)\n",
      "1 ROUGE-1 Average_P: 0.50696 (95%-conf.int. 0.49036 - 0.52454)\n",
      "1 ROUGE-1 Average_F: 0.29275 (95%-conf.int. 0.28149 - 0.30372)\n",
      "---------------------------------------------\n",
      "1 ROUGE-2 Average_R: 0.08911 (95%-conf.int. 0.08084 - 0.09830)\n",
      "1 ROUGE-2 Average_P: 0.18710 (95%-conf.int. 0.17395 - 0.20229)\n",
      "1 ROUGE-2 Average_F: 0.10662 (95%-conf.int. 0.09880 - 0.11491)\n",
      "---------------------------------------------\n",
      "1 ROUGE-L Average_R: 0.20565 (95%-conf.int. 0.19380 - 0.21763)\n",
      "1 ROUGE-L Average_P: 0.43912 (95%-conf.int. 0.42397 - 0.45664)\n",
      "1 ROUGE-L Average_F: 0.24970 (95%-conf.int. 0.24002 - 0.25936)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "abs_args_dict = arg_params\n",
    "\n",
    "abs_args_dict.update({\n",
    "            'bert_data_path':'./data',\n",
    "    'log_file':'./logs/abs_bertextabs_trained',\n",
    "    'model_path':'./model_files/trained/abs_bertextabs/',\n",
    "    'result_path':'./results/trained/abs_bertextabs',\n",
    "    'test_from':f'./model_files/trained/abs/model_step_148020.pt',\n",
    "    'task':'abs',\n",
    "    'mode':'test',\n",
    "    'batch_size':300,\n",
    "    'test_batch_size':200,\n",
    "    'max_pos':512,\n",
    "    'max_length':200,\n",
    "    'alpha': 0.95,\n",
    "    'min_length':50,\n",
    "        \n",
    "    'sep_optim':True,\n",
    "    'user_interval':True\n",
    "\n",
    "})\n",
    "\n",
    "args = Namespace(**abs_args_dict)\n",
    "\n",
    "# Generating and scoring the abstractive summaries using the trained Bert model\n",
    "test_abs(args, device_id=-1, pt=args.test_from, step=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:.1px solid grey\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='matchsum'></a>\n",
    "# Matchsum\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Source**:\n",
    "\n",
    "Code: https://github.com/maszhongming/MatchSum/\n",
    "\n",
    "\n",
    "Paper: https://arxiv.org/abs/2004.08795\n",
    "\n",
    "Description:\n",
    "\n",
    "This method performs Semantic text matching to estimate semantic similarity between a source and a target text fragment. It is trained on the CNN/ Daily Mail dataset and uses a Siamese-BERT (Bidirectional Encoder Representations from Transformers) architecture to compute the similarity between several candidate summaries to the source document and seledt the best candidate summary. A Siamese networks consists of two identical neural networks, each taking one of the two input inputs. The last layers of the two networks are then fed to a contrastive loss function , which calculates the similarity between the two inputs. Siamese BERT leverages the pre-trained BERT in a Siamese network structure to derive semantically meaningful text embeddings that can be compared using cosine-similarity. The Siamese network is also used in a similar way usinf the RoBERTa pretrained model \n",
    "\n",
    "Environment setup script - https://github.com/gufranpathan/case_law_g45/blob/master/matchsumm_env_setup.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Candidates\n",
    "\n",
    "Here we select candidate summaries, generated from the opinions, to be compared with the headnotes. From the multiple candidate summaries it selects the best cadidate summary based on the ROUGE score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocess.get_candidate import get_candidates_mp\n",
    "from argparse import Namespace\n",
    "import json\n",
    "import shutil\n",
    "import os\n",
    "from preprocess.train_matching import test_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "args_dict = {'data_path':'matchsumm_data/match_summ_sample.json',\n",
    "            'index_path':'matchsumm_data/sentence_id.json',\n",
    "            'write_path':'data/test_CNNDM_bert.jsonl',\n",
    "            'tokenizer':'bert'}\n",
    "args = Namespace(**args_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "shutil.rmtree('./temp') if os.path.isdir('./temp') else None\n",
    "get_candidates_mp(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score on pre-trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "args_dict = {'mode':'test',\n",
    "'encoder':'bert',\n",
    "'save_path':'matchsumm_models/',\n",
    "            'candidate_num':20,\n",
    "            'gpus':0,\n",
    "            'encoder':'bert'}\n",
    "args = Namespace(**args_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start loading datasets !!!\n",
      "Finished in 0:00:00.152812\n",
      "Information of dataset is:\n",
      "In total 1 datasets:\n",
      "\ttest has 369 instances.\n",
      "\n",
      "Current model is MatchSum_cnndm_bert.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/case_law_g45/venv/lib64/python3.6/site-packages/torch/serialization.py:657: SourceChangeWarning: source code of class 'transformers.modeling_bert.BertModel' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/data/case_law_g45/venv/lib64/python3.6/site-packages/torch/serialization.py:657: SourceChangeWarning: source code of class 'transformers.modeling_bert.BertEmbeddings' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/data/case_law_g45/venv/lib64/python3.6/site-packages/torch/serialization.py:657: SourceChangeWarning: source code of class 'torch.nn.modules.normalization.LayerNorm' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/data/case_law_g45/venv/lib64/python3.6/site-packages/torch/serialization.py:657: SourceChangeWarning: source code of class 'torch.nn.modules.container.ModuleList' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/data/case_law_g45/venv/lib64/python3.6/site-packages/torch/serialization.py:657: SourceChangeWarning: source code of class 'transformers.modeling_bert.BertSelfAttention' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/data/case_law_g45/venv/lib64/python3.6/site-packages/torch/serialization.py:657: SourceChangeWarning: source code of class 'torch.nn.modules.linear.Linear' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/data/case_law_g45/venv/lib64/python3.6/site-packages/torch/serialization.py:657: SourceChangeWarning: source code of class 'torch.nn.modules.activation.Tanh' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "369/369 (100.00%) decoded in 0:11:54 seconds\n",
      "Start writing files !!!\n",
      "Start evaluating ROUGE score !!!\n",
      "---------------------------------------------\n",
      "1 ROUGE-1 Average_R: 0.33545 (95%-conf.int. 0.31925 - 0.35333)\n",
      "1 ROUGE-1 Average_P: 0.79428 (95%-conf.int. 0.78238 - 0.80488)\n",
      "1 ROUGE-1 Average_F: 0.44129 (95%-conf.int. 0.42646 - 0.45706)\n",
      "---------------------------------------------\n",
      "1 ROUGE-2 Average_R: 0.24185 (95%-conf.int. 0.22784 - 0.25637)\n",
      "1 ROUGE-2 Average_P: 0.58127 (95%-conf.int. 0.56360 - 0.59731)\n",
      "1 ROUGE-2 Average_F: 0.31916 (95%-conf.int. 0.30535 - 0.33325)\n",
      "---------------------------------------------\n",
      "1 ROUGE-L Average_R: 0.31068 (95%-conf.int. 0.29551 - 0.32740)\n",
      "1 ROUGE-L Average_P: 0.74182 (95%-conf.int. 0.72769 - 0.75541)\n",
      "1 ROUGE-L Average_F: 0.40957 (95%-conf.int. 0.39584 - 0.42462)\n",
      "\n",
      "Evaluate data in 730.31 seconds!\n",
      "[tester] \n",
      "MatchRougeMetric: ROUGE-1=0.44129, ROUGE-2=0.31916, ROUGE-L=0.40957\n",
      "Current model is MatchSum_cnndm_roberta.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/case_law_g45/venv/lib64/python3.6/site-packages/torch/serialization.py:657: SourceChangeWarning: source code of class 'transformers.modeling_roberta.RobertaEmbeddings' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "369/369 (100.00%) decoded in 0:11:48 seconds\n",
      "Start writing files !!!\n",
      "Start evaluating ROUGE score !!!\n",
      "---------------------------------------------\n",
      "1 ROUGE-1 Average_R: 0.43630 (95%-conf.int. 0.41940 - 0.45346)\n",
      "1 ROUGE-1 Average_P: 0.77631 (95%-conf.int. 0.76389 - 0.78864)\n",
      "1 ROUGE-1 Average_F: 0.52943 (95%-conf.int. 0.51599 - 0.54246)\n",
      "---------------------------------------------\n",
      "1 ROUGE-2 Average_R: 0.32228 (95%-conf.int. 0.30765 - 0.33644)\n",
      "1 ROUGE-2 Average_P: 0.57995 (95%-conf.int. 0.56391 - 0.59588)\n",
      "1 ROUGE-2 Average_F: 0.39246 (95%-conf.int. 0.37956 - 0.40653)\n",
      "---------------------------------------------\n",
      "1 ROUGE-L Average_R: 0.40682 (95%-conf.int. 0.39012 - 0.42230)\n",
      "1 ROUGE-L Average_P: 0.72883 (95%-conf.int. 0.71508 - 0.74245)\n",
      "1 ROUGE-L Average_F: 0.49484 (95%-conf.int. 0.48198 - 0.50785)\n",
      "\n",
      "Evaluate data in 727.33 seconds!\n",
      "[tester] \n",
      "MatchRougeMetric: ROUGE-1=0.52943, ROUGE-2=0.39246, ROUGE-L=0.49484\n"
     ]
    }
   ],
   "source": [
    "shutil.rmtree('./temp') if os.path.isdir('./temp') else None\n",
    "shutil.rmtree('data/result/') if os.path.isdir('data/result/') else None\n",
    "\n",
    "# generating and evaluating extractive summaries on the pre-trained model\n",
    "test_model(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our Results (F-Scores)\n",
    "\n",
    "\n",
    "|SOTA|Type|Transformer|(Pre-trained) ROUGE-1|(Pre-trained) ROUGE-2|(Pre-trained) ROUGE-L|(Trained) ROUGE-1|(Trained) ROUGE-2|(Trained) ROUGE-L|\n",
    "|:--------------|:-|:-|:-:|:-:|:-:|:-:|:-:|:-:|\n",
    "|PreSumm|Extractive|BERT|0.29475|0.11580|0.25311|0.30204|0.12198|0.26038|\n",
    "| |Abstractive|Baseline Transformer|0.24971|0.07703|0.21326|0.27616|0.11064|0.23477|\n",
    "|\t|\t|BERT|0.24623|0.07836|0.21218|0.29275|0.10662|0.24970|\n",
    "|MatchSum|Extractive|BERT|0.44129|0.31916|0.40957|-|-|-|\n",
    "|\t\t| |RoBERTa|0.52943|0.39246|0.49484|-|-|-|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Comment*\n",
    "*The table shows the ROUGE scores for the various models. Our PreSumm trained models do very well compared to the pre-trained ROUGE scores.  \n",
    "For MatchSum we show the ROUGE Score for extracted summaries using the BERT and RoBERTa pretrained models.  \n",
    "The MatchSum RoBERTa produced the highest scores.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample Results (PreSumm)\n",
    "\n",
    "**Actual Headnote:**  \n",
    "\n",
    "<font color='red'>**the trial court lacked jurisdiction to extend defendants period of probation**</font> , <font color='blue'>we arrest judgment and vacate **the order modifying probation and imposing sentence**</font><q>on 21 july 2008 , defendant pled guilty to six counts of breaking or entering a motor vehicle and , in a combined judgment , was sentenced to two consecutive terms of six to eight months each<q>defendants probation expiration date was 20 july 2010 . on 1 march 2010 , defendants probation officer filed two new probation violation reports in the office of the clerk of superior court .  \n",
    "\n",
    "**Generated Headnote (Abstractive):**  \n",
    "\n",
    "probation and parole lack of jurisdiction judgment arrested order vacated <font color='red'>**the trial court lacked jurisdiction to extend defendants period of probation**</font> .<q><font color='blue'>judgment was arrested and **the order modifying probation and imposing sentence** was vacated</font>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Comment*\n",
    "\n",
    "*In this PreSumm headnote sample we see two similar segments. The first is about how the trial court lacked jurisdiction to extend defendants period of probation verbatim. The second is referencing the arrest judgment and to vacate the order modifying probation and imposing sentence.*  \n",
    "\n",
    "*We can see the abstractive quality of the PreSumm generated headnote by the fragmented sentences in the initial words.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample Results (MatchSum)\n",
    "\n",
    "**Actual Headnote:**  \n",
    "\n",
    "employer and employee -- non-compete agreement -- client-based -- unreasonable the trial court correctly granted defendant 's motion for a dismissal under n.c.g.s. § 1a-1 , rule 12 ( b ) ( 6 ) of an action arising from a non-compete agreement where the client-based territorial restriction and the five-year time limitation in the agreement were unreasonable .although a five-year time restriction may be upheld , it must be considered with its geographical scope .here , the physical scope of the territorial restriction is irrelevant , but the substitution of the client base is unreasonable because it <font color='red'>**prevents** defendant **from working for all of** plaintiff 's **current or recent clients , regardless of location**</font> , so that he is precluded from working with a number of businesses in a large number of cities throughout the world .<font color='orange'>**considering** the **relatively small number of** plaintiff 's **clients** with whom defendant **worked**</font> , <font color='blue'>**the scope is extreme**</font> .furthermore , the restriction is unduly vague.  \n",
    "\n",
    "**Generated Headnote:**  \n",
    "\n",
    "the covenant in question <font color='red'>**prevents** mr. baskin **from working for all of** farr 's **current or recent clients , regardless of** where the client is **located**</font> , whether he had any contact with them , or whether he even knew about them .<font color='blue'>**the scope** of the covenant **is extreme**</font> , <font color='orange'>**considering** that mr. baskin only **worked** with a **relatively small number of** farr 's **clients**</font> ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Comment*\n",
    "\n",
    "*Here we share an actual headnotes with the generated headnotes using the MatchSum model. We see three segments that are related. The first is about the prevention of the defendant from working for all of plaintiff's current or recent clients, regardless of location. Next, the generated summary references the extreme scope. Lastly, it references the relatively small number of clients with whom defendant worked with.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For the PreSumm model, based on the ROUGE score we observe  \n",
    " - The extractive model performs better than the abstractive based model  \n",
    " - The trained model performs slightly better than the pretrained model  \n",
    "\n",
    "- For the MathSum model , based on the ROUGE score we observe\n",
    " - RoBERTa model performs better than the BERT model  \n",
    "\n",
    "- Over all the MathSum model performed better than the PreSumm model  \n",
    "\n",
    "- This is also evident from samples of headnotes that we saw where we can find more sentences match the headnotes when we use the MathSum model than when we use the PreSumm model  \n",
    "\n",
    "- The MathSum RoBERTa model performed the best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next Steps\n",
    "\n",
    "1. Tuning the different hype parameters  \n",
    "1. Expanding the sentence length beyond the fixed limit of 512  \n",
    "1. Using all the cases  \n",
    "1. Using all the opinions  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROUGE Score and Metrics\n",
    "\n",
    "The models use the three Rouge scores is comprised of three metrics, which are used for evaluating the summarization of texts. It works by comparing generated summaries against reference summaries.  \n",
    "\n",
    "Recall is how much of the reference summary is the generated summary capturing.  \n",
    "\n",
    "However, generated summaries could get too long, capturing all words in the reference summary with many additional useless words. Precision is used to prevent this.  \n",
    "\n",
    "Assigned by equal importance of recall and precision, i.e. alpha=0.5, is how the f-measure is computed.  \n",
    "\n",
    "The three Rouge scores: ROUGE-1, ROUGE-2, and ROUGE-L. ROUGE-1 measures the overlap of words, ROUGE-2 measures the overlap of two consecutive words, and ROUGE-L measures longest matching sequence of words.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Types of Summarizations\n",
    "\n",
    "- **Extraction-based summarization:** Content is extracted from original document and is not modified. This method will extract key phrases or sentences to form a summary. The summary generated by this method may not be the same format as a human might express  it and the sentences may appear disjointed  \n",
    "\n",
    "- **Abstraction-based summarization:** Abstractive methods generate a summary based on internal semantic representation of the original content, closer to what a human might express. Abstraction may transform the extracted content. Such transformation are computationally very challenging, involving both NLP (natural language processing) and a deep understanding of the document  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-Trained Models\n",
    "\n",
    "**BERT (Bidirectional Encoder Representations from Transformers)**  \n",
    "\n",
    "BERT is a NLP technique developed by Google(published in 2018 by Jacob Devlin and his colleagues) which can be used to created pretrained language models.  This technigque hae reently been used to create pretrained models for a wide range of natural language processing tasks.  BERT is a deeply bidirectional, unsupervised language representation and these models are  pre-trained using only a plain text corpus. BERT uses a masking stategy and learns to predict masked sections within the text  \n",
    "\n",
    "**RoBERTa (Robustly Optimized BERT Pretraining Approach)**  \n",
    "\n",
    "RoBERTa builds on BERT’s language masking strategy. It modifies key hyperparameters in BERT, removing BERT’s next-sentence pretraining objective, and training with much larger mini-batches and learning rates. This allows RoBERTa to improve on the masked language modeling objective compared with BERT and leads to better downstream task performance. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bibliography\n",
    "\n",
    "Extractive Summarization as Text Matching Ming Zhong∗ , Pengfei Liu∗ , Yiran Chen, Danqing Wang, Xipeng Qiu† , Xuanjing Huang Shanghai Key Laboratory of Intelligent Information Processing, Fudan University.  \n",
    "\n",
    "Text Summarization with Pretrained Encoders Yang Liu and Mirella Lapata Institute for Language, Cognition and Computation School of Informatics, University of Edinburgh."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
